---
title: "Testing and Debugging"
---

{{< include _common.qmd >}}

## Last Time: Optimization

:::: {.columns}

::: {.column width="47%"}

### Gradient Descent

Few assumptions on $f$, cheap iterations, but slow convergence.

\medskip\pause

\begin{algorithm}[H]
  \caption{Gradient descent}
  \KwData{Step size $t > 0$}
  \Repeat{convergence}{
    $x \gets x - t \nabla f(x)$\;
  }
  \Return{$x$}
\end{algorithm}

:::

. . .

::: {.column width="47%"}

### Newton's Method

Requires second derivatives, expensive iterations, but fast convergence.

\medskip\pause

\begin{algorithm}[H]
  \caption{Newton method}
  \KwData{Step size $t > 0$}
  \Repeat{convergence}{
    $x \gets x - t \big(\nabla^2 f(x))^{-1} \nabla f(x)$\;
  }
  \Return{$x$}
\end{algorithm}

:::

::::

## Today

### Testing

How do we know our code is correct?

. . .

### Debugging

How do we find and fix bugs in our code?

# Testing

## Testing

Testing is the process of executing a program with the intent of finding bugs.

\medskip\pause

We have already done testing using plots and `all.equal()`.

\medskip\pause

But this is slightly ad-hoc. We can do better!

\medskip\pause

We want automatic and reproducible testing that we can run as part of our
workflow.

## What is a Test?

A test is a function that checks that some property holds.

\medskip\pause

Typically, we have output from some function and want to check that it meets
our expectations.

## Automated Testing

So far, we have been testing manually.

\medskip\pause

But what we want is automated testing, which we can make part of our workflow.

\medskip\pause

### Suggested Workflow

\medskip

\begin{center}
  \begin{tikzpicture}[node distance=2cm,>=stealth,rounded corners]
    \node (A) [draw, rectangle] {Write code};
    \node (B) [draw, rectangle, right of=A, node distance=4.5cm] {Write tests};
    \node (C) [draw, rectangle, right of=B, node distance=4.5cm] {Run tests};
    \node (D) [draw, diamond, aspect=2, below of=C, node distance=2.5cm] {Tests pass?};
    \node (F) [draw, rectangle, left of=D, node distance=4.5cm] {Fix code (debug)};

    \draw[->] (A) -- (B);
    \draw[->] (B) -- (C);
    \draw[->] (C) -- (D);
    \draw[->] (D) -- ++(0,-1) node[pos=0.8, below] {Yes} -| (A);
    \draw[->] (D) -- node[above] {No} (F);
    \draw[->] (F) -- (B);
  \end{tikzpicture}
\end{center}


## The testthat Package

:::: {.columns}

::: {.column width="70%"}

The `testthat` package makes it easy to write and run tests in R.

\medskip\pause

It provides a simple syntax for writing tests and integrates well with RStudio.

\medskip\pause

It is also the most common testing framework for R packages.

:::

::: {.column width="20%"}

![](../images/testthat.png){width=100%}
:::

::::

## Writing Tests with testthat

Tests in **testthat** are written using the `test_that()` function.

\medskip\pause

Inside the `test_that()` function, we use `expect_*()` functions to check that
certain conditions hold.

```{r}
library(testthat)

test_that("sum works", {
  expect_identical(sum(1, 2), 3)
  expect_identical(sum(-1, 1), 0)
})
```

## Test Failures

If a test fails, `testthat` will throw an error and provide information about
the failure.

. . .

```{r}
#| error: true
test_that("sum works", {
  expect_identical(sum(1, 2), 4) # This will fail
})
```

## Organizing Tests

In your test directory, you can organize tests into multiple files.

\medskip\pause

\dirtree{%
  .1 ./.
  .2 tests/.
  .3 test-sum.R.
  .3 test-mean.R.
}

. . .

### Convention

Test files should be named `test-*.R` (or `test_*.R`), where `*` is a
descriptive name for the tests in that file.

## `test_dir()`

`testthat::test_dir()` runs all the tests in a specified directory.

. . .

```{r}
testthat::test_dir(here::here("tests"))
```

## Inside Packages

:::: {.columns}

::: {.column width="46%"}

**testthat** was designed to be used inside R packages.

\medskip\pause

Tests are organized in files inside the `tests/testthat/` directory of an
R package.

:::

::: {.column width="46%"}

\dirtree{%
  .1 mypkg/.
  .2 R/.
  .2 tests/.
  .3 testthat/.
  .4 test-sum.R.
  .4 test-mean.R.
}

:::

::::

\bigskip\pause

We will see more about package development later in the course.

## Test Coverage

:::: {.columns}

::: {.column width="47%"}

We want to test as many parts of our code as possible.

\medskip\pause

This is called test coverage.

\medskip\pause

### covr

Tracks which lines of code are executed when we run our tests.

\medskip

\alert{Out of scope} for this course, but you can read more about it in the
[covr documentation](https://covr.r-lib.org/).

:::

::: {.column width="47%"}

![Test coverage report.](../images/code-coverage.png){width=100%}

:::

::::

## Reproducibility

We want our tests to be reproducible.

\medskip\pause

This means that they should give the same result every time we run them.

\medskip\pause

This is especially important for tests that involve randomness.

\medskip\pause

We can achieve this by setting a random seed using `set.seed()`.

## Numerical Tolerance

When comparing numerical values, we need to account for floating-point
precision.

\medskip\pause

```{r}
#| error: true
test_that("numerical equality", {
  expect_identical(sqrt(2)^2, 2)
})
```

\pause

Use `expect_equal()` with a specified tolerance to handle this.

```{r}
test_that("numerical equality with tolerance", {
  expect_equal(sqrt(2)^2, 2, tolerance = 1e-8)
})
```

# Debugging

## Debugging

Bugs are common, maybe inevitable.

\medskip\pause

Debugging is the process of finding and fixing bugs.

![Down the rabbit hole.](../images/xkcd-debugging.png){width=80%}

---

![The "first" bug report.](../images/first-bug-reduced.jpg){width=75%}

## Traceback

Sometimes it is enough to simply look at the call stack.

```{r}
# debugging.R
f <- function() g()
g <- function() h()
h <- function() stop("We have a problem!")
```

. . .

```{r}
#| error: true
f()
```
. . .

```{r}
#| eval: false
traceback()
```

```
4: stop("We have a problem!") at debugging.R#3
3: h() at debugging.R#2
2: g() at debugging.R#1
1: f()
```

## Poor Man's Debugging

Sprinkle print statements throughout your code:

```r
f <- function(x, y) {
  cat("x:\n")
  print(x)

  z <- g(x, y)

  cat("z:\n")
  print(z)

  list(sum_z = sum(z))
}
```

. . .

Okay in the simplest of cases and easy to get going with, but will cost you more
time in the long run.

## Returning Diagnostics

For more complex functions, adding a `debug`/`diagnostics` flag, which if `TRUE`
returns some extra output.

\medskip\pause

```{r}
f <- function(x, y, debug = FALSE) {
  z <- g(x, y)

  out <- list(sum_z = sum(z), diagnostics = NULL)

  if (debug) {
    out$diagnostics <- list(z = z)
  }

  out
}
```

## Interactive Debugging

For more complex problems, you typically need to debug interactively.

\medskip\pause

There are two common ways to debug code interactively in R.

. . .

:::: {.columns}

::: {.column width="47%"}

### Browser

`browser()` can be inserted anywhere in the code.

\medskip\pause

When execution reaches `browser()`, it stops and enters debug mode.

:::

. . .

::: {.column width="47%"}

### RStudio Breakpoints

Visual breakpoints can be set in RStudio by clicking in the margin next to a
line number.

\medskip\pause

When execution reaches a breakpoint, it stops and enters debug mode.

\medskip\pause

No need to modify the code, but cannot be conditionally set.

:::

::::

## AI Debugging

Debugging with AI (Copilot, Claude, Gemini etc.) is a quick and easy way to
debug.

\medskip\pause

Make sure to provide context, especially when working with statistical topics.

\medskip\pause

AIs are typically good at finding syntax errors, but not so good at finding
algorithmic errors.

\medskip\pause

Will almost always try to be helpful, so may provide incorrect answers and find
bugs that are not there.

## Pair Debugging

Pair debugging is a collaborative debugging technique where you work in a pair
to find and fix bugs.

\medskip\pause

One person walks through the code, explaining it line-by-line, while the other
listens and asks questions.

\medskip\pause

This can help you see the code from a different perspective and find bugs that
you might have missed.

## Rubber Duck Debugging

:::: {.columns align="center"}

::: {.column width="54%"}

If you don't have anyone around to pair up with, you can always team up with a
rubber duck!

:::

::: {.column width="40%"}

\begin{figure}
  \begin{tikzpicture}
    \duck[stethoscope=gray!80!black]
  \end{tikzpicture}
\end{figure}

:::

::::


\bigskip\pause

The idea is that explaining the code out loud helps you see it from a different
perspective.


# Worked Example

## Poisson Regression

We are going to fit a Poisson regression model using two different methods:
gradient descent and Newton's method.

\medskip\pause

The Poisson regression model is given by
$$
\E(\symbf{y} \mid \symbf{X}) = \exp(\symbf{X} \symbf{\beta}),
$$
where $\symbf{X}$ is a $n \times p$ matrix of predictors and $\symbf{y}$ is
our response.

\medskip\pause

The problem is to find
$$
\hat{\symbf{\beta}} = \argmin_{\symbf{\beta}} \left( \frac{1}{n} \sum_{i=1}^n \exp(\symbf{x}_i^T \symbf{\beta}) - y_i \symbf{x}_i^T \symbf{\beta} \right).
$$

. . .

This is a convex optimization problem.

## Data

Here, we will generate some synthetic data, for a simple Poisson regression
model with one predictor.

```{r poisson-regression}
n <- 1000
x <- rnorm(n)
y <- rpois(n, exp(x))
X <- model.matrix(y ~ x)

head(X, 5)
```

## Implementation of Objective and Gradient

```{r poisson-implementations}
objective <- function(beta, X, y) {
  Xty <- drop(crossprod(X, y))
  (sum(exp(X %*% beta)) - beta %*% Xty) / nrow(X)
}

gradient <- function(beta, X, y) {
  Xty <- drop(crossprod(X, y))
  (colSums(drop(exp(X %*% beta)) * X) - Xty) / nrow(X)
}
```

## Implementations of Optimization Algorithms

Gradient descent and Newton method implementations can be found in
[`debugging.R`](R/debugging.R).

```{r source-debugging-file, cache=FALSE}
source(here::here("R", "debugging.R"))
```

## Testing

Let's run the gradient descent implementation to see if it works.

:::: {.columns}

::: {.column width="47%"}

```{r run-gd}
res_gd <- gradient_descent(
  c(0, 0),
  objective,
  gradient,
  t0 = 1,
  epsilon = 1e-8,
  X = X,
  y = y
)

res_glm <- glm(
  y ~ x,
  family = "poisson"
)
```

:::

. . .

::: {.column width="47%"}

```{r}
res_gd$par
coef(res_glm)
```

:::

::::


## Buggy Newton Method

First, we define the Hessian function.

```{r def-hessian}
hessian <- function(beta, X, y) {
  (crossprod(X, drop(exp(X %*% beta)) * X)) / nrow(X)
}
```

. . .

Then, we can run the Newton method implementation: `newton_method()`.

## Exercise: Debugging `newton_method()`

1. Download and open [`debugging.R`](R/debugging.R) in RStudio. \pause
2. Create another script, and place some code for generating data there.\pause
3. Source `debugging.R` and test that `gradient_descent()` works. Now try
   `newton_method()`. What happens?\pause
4. Create a test for the `newton_method()` function using the `testthat` package
   that fails.\pause
5. Start debugging by setting some breakpoints in `newton_method()`.\pause
6. Run `newton_method()` again. Execution should stop at the first breakpoint.
   Use the RStudio interface to step through the code and inspect variables.
   What do you see?\pause
7. There are two bugs in `newton_method()`. Can you find and fix them?

## Next Time

### Likelihood Optimization

We study a practical example of optimizing a multinomial likelihood.

\medskip\pause

We will introduce algorithms for solving constrained optimization problems.
