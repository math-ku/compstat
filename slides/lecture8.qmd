---
title: "Testing And Debugging"
format:
  beamer:
    mermaid:
      theme: neutral
---

{{< include _common.qmd >}}

## Last Time: Optimization

:::: {.columns}

::: {.column width="47%"}

### Gradient Descent

\begin{algorithm}[H]
  \caption{Gradient descent}
  \KwData{Step size $t > 0$}
  \Repeat{convergence}{
    $x \gets x - t \nabla f(x)$\;
  }
  \Return{$x$}
\end{algorithm}

. . .

Few assumptions on $f$, cheap iterations, but slow convergence.

:::

. . .

::: {.column width="47%"}

### Newton Method

\begin{algorithm}[H]
  \caption{Newton method}
  \KwData{Step size $t > 0$}
  \Repeat{convergence}{
    $x \gets x - t \big(\nabla^2 f(x))^{-1} \nabla f(x)$\;
  }
  \Return{$x$}
\end{algorithm}

. . .

Requires second derivatives, expensive iterations, but fast convergence.

:::

::::


# Testing

## Testing

Testing is the process of executing a program with the intent of finding bugs.

\medskip\pause

We have already done testing using plots and `all.equal()`.

\medskip\pause

But this is slightly ad-hoc. We can do better!

\medskip\pause

We want automatic and reproducible testing that we can run as part of our
workflow.

## What is a Test?

A test is a function that checks that some property holds.

\medskip\pause

Typically, we have output from some function and want to check that it meets
our expectations.

## Automated Testing

:::: {.columns align="center"}

::: {.column width="53%"}

So far, we have been testing manually.

\medskip\pause

But what we want is automated testing, which we can make part of our workflow.

\medskip

We also want to do this **effortlessly**.

:::

::: {.column width="40%"}


```{mermaid}
%%| echo: false
%%| fig-height: 3.2
graph TD;
  A[Write code] --> B[Write tests];
  B --> C[Run tests];
  C --> D{Tests pass?};
  D -- Yes --> A;
  D -- No --> F[Fix code];
  F --> B;
```


:::

::::


## The testthat Package

:::: {.columns}

::: {.column width="70%"}

The `testthat` package makes it easy to write and run tests in R.

\medskip\pause

It provides a simple syntax for writing tests and integrates well with RStudio.

\medskip\pause

It is also the standard testing framework for R packages.

:::

::: {.column width="20%"}

![](../images/testthat.png){width=100%}
:::

::::

## Writing Tests with testthat

Tests in **testthat** are written using the `test_that()` function.

\medskip\pause

Inside the `test_that()` function, we use `expect_*()` functions to check that
certain conditions hold.

```{r}
library(testthat)

test_that("sum works", {
  expect_identical(sum(1, 2), 3)
  expect_identical(sum(-1, 1), 0)
})
```

## Test Failures

If a test fails, `testthat` will throw an error and provide information about
the failure.

. . .

```{r}
#| error: true
test_that("sum works", {
  expect_identical(sum(1, 2), 4) # This will fail
})
```

## Organizing Tests

In your test directory, you can organize tests into multiple files.

\medskip\pause

\dirtree{%
  .1 tests/.
  .2 test-sum.R.
  .2 test-mean.R.
}

. . .

## `test_dir()`

`testthat::test_dir()` runs all the tests in a specified directory.

. . .

```{r}
testthat::test_dir(here::here("tests"))
```

## Inside Packages

:::: {.columns}

::: {.column width="46%"}

testthat was designed to be used inside R packages, and it integrates well with
the package development workflow.

\medskip\pause

Tests are typically organized in files inside the `tests/testthat/` directory of
an R package.


:::

::: {.column width="46%"}

\dirtree{%
  .1 mypkg/.
  .2 R/.
  .2 tests/.
  .3 testthat/.
  .4 test-sum.R.
  .4 test-mean.R.
}

:::

::::


## Test Coverage

:::: {.columns}

::: {.column width="47%"}

We want to test as many parts of our code as possible.

\medskip\pause

This is called test coverage.

\medskip\pause

We can measure tes coverage using the `covr` package, which tracks which lines
of code are executed when we run our tests.

\medskip\pause

:::

::: {.column width="47%"}

![Test coverage report.](../images/code-coverage.png){width=100%}

:::

::::

## Reproducibility

We want our tests to be reproducible.

\medskip\pause

This means that they should give the same result every time we run them.

\medskip\pause

This is especially important for tests that involve randomness.

\medskip\pause

We can achieve this by setting a random seed using `set.seed()`.

## Numerical Tolerance

When comparing numerical values, we need to account for floating-point
precision.

\medskip\pause

We've seen this before when comparing kernel density estimates.

\medskip\pause

# Debugging

## Debugging

Bugs are common, maybe inevitable.

\medskip\pause

Debugging is the process of finding and fixing bugs.

![Down the rabbit hole.](../images/xkcd-debugging.png){width=80%}

---

![The "first" bug.](../images/first-bug-reduced.jpg){width=75%}

## Traceback

Sometimes it is enough to simply look at the call stack.

```{r}
# debugging.R
f <- function() g()
g <- function() h()
h <- function() stop("We have a problem!")
```

. . .

```{r}
#| error: true
f()
```
. . .

```{r}
#| eval: false
traceback()
```

```
4: stop("We have a problem!") at debugging.R#3
3: h() at debugging.R#2
2: g() at debugging.R#1
1: f()
```

## Entering Debug Mode

Two common ways to enter debug mode:

- `browser()`: Stops execution and enters debug mode
- Set a breakpoint in RStudio.

. . .

:::: {.columns}

::: {.column width="47%"}

### Browser

`browser()` can be inserted anywhere in the code.

\medskip\pause

When execution reaches `browser()`, it stops and enters debug mode.

:::

. . .

::: {.column width="47%"}

### RStudio Breakpoints

Visual breakpoints can be set in RStudio by clicking in the margin next to the
line number.

\medskip\pause

When execution reaches a breakpoint, it stops and enters debug mode.

\medskip\pause

No need to modify the code, but cannot be conditionally set.

:::

::::

## Debugging C++ Code (Rcpp)

- Unfortunately **not** easy.
- General problem is that C++ code is compiled, so what you see in C++ is not
  necessarily what is executed.
- We won't cover it here, but it **is** possible: see
  [these notes](https://github.com/wch/r-debug/blob/master/debugging-r.md) for
  instance.

# Worked Example

## Poisson Regression

We are going to fit a Poisson regression model using two different methods:
gradient descent and Newton's method.

\medskip\pause

The Poisson regression model is given by
$$
\E(Y \mid X = x) = \exp(x^T \beta).
$$

. . .

The problem is to find
$$
\hat{\beta} = \argmin_\beta \left( \frac{1}{n} \sum_{i=1}^n \exp(x_i^T \beta) - y_i x_i^T \beta \right).
$$

. . .

This is a convex optimization problem.

## Data

```{r poisson-regression}
n <- 1000
x <- rnorm(n)
y <- rpois(n, exp(x))
X <- model.matrix(y ~ x)

head(X, 5)
```

## Implementation of Objective and Gradient

```{r poisson-implementations}
Xty <- drop(crossprod(X, y))

objective <- function(beta) {
  (sum(exp(X %*% beta)) - beta %*% Xty) / nrow(X)
}

gradient <- function(beta) {
  (colSums(drop(exp(X %*% beta)) * X) - Xty) / nrow(X)
}
```

## Implementations of Optimization Algorithms

Gradient descent and Newton method implementations can be found in
[`debugging.R`](R/debugging.R).

```{r source-debugging-file, cache=FALSE}
source(here::here("R/debugging.R"))
```

## Testing

We can run the gradient descent implementation to see if it works.

```{r run-gd}
gradient_descent(
  c(0, 0),
  objective,
  gradient,
  t0 = 1,
  epsilon = 1e-8
)

glm(y ~ x, family = "poisson")
```

## Buggy Newton Method

```{r def-hessian}
hessian <- function(beta) {
  (crossprod(X, drop(exp(X %*% beta)) * X)) / nrow(X)
}
```

```{r run-newton, error=TRUE, linewidth = 80}
newton_method(c(0, 0), objective, gradient, hessian)
```

## Exercise: Debugging `newton_method()`

- Download and open [`debugging.R`](R/debugging.R) in RStudio.
- Create another script and define `objective()`, `gradient()`, and `hessian()`
  by copying from these slides.
- Source `debugging.R` and test that `gradient_descent()` works. Now try
  `newton_method()`. Oh no, there's an error!
- Insert a breakpoint before the `while` loop and inspect the values of
  `objective(x_new)`, `values`, `alpha`, `beta` and `grad_d_prod` from within
  the browser.
- Explain and fix the bug. Remove the breakpoint.
- Source the fixed code and try calling `newton_method()`. What happens?
- Debug the code again, using breakpoints or `browser()`. Finally verify that
  `newton_method()` works.

