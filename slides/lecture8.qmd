---
title: "Testing And Debugging"
format:
  beamer:
    mermaid:
      theme: neutral
---

{{< include _common.qmd >}}

## Last Time: Optimization


### Gradient Descent

Iterative algorithm to find a local minimum of a differentiable function

. . .

\begin{algorithm}[H]
  \caption{Gradient descent}
  \KwData{Step size $t > 0$}
  \Repeat{convergence}{
    $x \gets x - t \nabla f(x)$\;
  }
  \Return{$x$}
\end{algorithm}

. . .

## Newton Method

Iterative algorithm to find a local minimum of a twice-differentiable function

. . .

\begin{algorithm}[H]
  \caption{Newton method}
  \KwData{Tolerance $\epsilon > 0$}
  \Repeat{convergence}{
    $d \gets -H_f(x)^{-1} \nabla f(x)$\;
    $\alpha \gets 1$\;
    \While{$f(x + \alpha d) > f(x) + 0.1 \alpha \nabla f(x)^T d$}{
      $\alpha \gets 0.5 \alpha$\;
    }
    $x \gets x + \alpha d$\;
  }
  \Return{$x$}
\end{algorithm}

# Testing

## Testing

Testing is the process of executing a program with the intent of finding bugs.

\medskip\pause

We have already done testing using plots and `all.equal()`.

\medskip\pause

But this is slightly ad-hoc. We can do better!

\medskip\pause

We want automatic and reproducible testing that we can run as part of our
workflow.

## What is a Test?

A test is a function that checks that some property holds.

\medskip\pause

Typically, we have output from some function and want to check that it meets
our expectations.

## Automated Testing

:::: {.columns align="center"}

::: {.column width="53%"}

So far, we have been testing manually.

\medskip\pause

But what we want is automated testing, which we can make part of our workflow.

\medskip

We also want to do this **effortlessly**.

:::

::: {.column width="40%"}


```{mermaid}
%%| echo: false
%%| fig-height: 3.2
graph TD;
  A[Write code] --> B[Write tests];
  B --> C[Run tests];
  C --> D{Tests pass?};
  D -- Yes --> A;
  D -- No --> F[Fix code];
  F --> B;
```


:::

::::


## The testthat Package

:::: {.columns}

::: {.column width="70%"}

The `testthat` package makes it easy to write and run tests in R.

\medskip\pause

It provides a simple syntax for writing tests and integrates well with RStudio.

\medskip\pause

It is also the standard testing framework for R packages.

:::

::: {.column width="20%"}

![](../images/testthat.png){width=100%}
:::

::::

## Writing Tests with testthat

Tests in **testthat** are written using the `test_that()` function.

\medskip\pause

Inside the `test_that()` function, we use `expect_*()` functions to check that
certain conditions hold.

```{r}
library(testthat)

test_that("sum works", {
  expect_identical(sum(1, 2), 3)
  expect_identical(sum(-1, 1), 0)
})
```

## Test Failures

If a test fails, `testthat` will throw an error and provide information about
the failure.

. . .

```{r}
#| error: true
test_that("sum works", {
  expect_identical(sum(1, 2), 4) # This will fail
})
```

## Organizing Tests

In your test directory, you can organize tests into multiple files.

\medskip\pause

\dirtree{%
  .1 tests/.
  .2 test-sum.R.
  .2 test-mean.R.
}

. . .

## `test_dir()`

`testthat::test_dir()` runs all the tests in a specified directory.

. . .

```{r}
testthat::test_dir(here::here("tests"))
```

## Inside Packages

:::: {.columns}

::: {.column width="46%"}

testthat was designed to be used inside R packages, and it integrates well with
the package development workflow.

\medskip\pause

Tests are typically organized in files inside the `tests/testthat/` directory of
an R package.

\medskip\pause

We will learn more about this when we cover package development.

:::

::: {.column width="46%"}

\dirtree{%
  .1 mypkg/.
  .2 R/.
  .2 tests/.
  .3 testthat/.
  .4 test-sum.R.
  .4 test-mean.R.
}

:::

::::


## Test Coverage

:::: {.columns}

::: {.column width="47%"}

We want to test as many parts of our code as possible.

\medskip\pause

This is called test coverage.

\medskip\pause

We can measure tes coverage using the `covr` package, which tracks which lines
of code are executed when we run our tests.

\medskip\pause

:::

::: {.column width="47%"}

![Test coverage report.](../images/code-coverage.png){width=100%}

:::

::::

## Reproducibility

We want our tests to be reproducible.

\medskip\pause

This means that they should give the same result every time we run them.

\medskip\pause

This is especially important for tests that involve randomness.

\medskip\pause

We can achieve this by setting a random seed using `set.seed()`.

## Numerical Tolerance

When comparing numerical values, we need to account for floating-point
precision.

\medskip\pause

We've seen this before when comparing kernel density estimates.

\medskip\pause

# Debugging

## Debugging

Bugs are common, maybe inevitable.

\medskip\pause

Debugging is the process of finding and fixing bugs.

![Down the rabbit hole.](../images/xkcd-debugging.png){width=80%}

---

![The "first" bug.](../images/first-bug-reduced.jpg){width=75%}

## Poisson Regression

```{r poisson-regression}
n <- 1000
x <- rnorm(n)
y <- rpois(n, exp(x))
X <- model.matrix(y ~ x)
```

. . .

```{r poisson-implementations}
Xty <- drop(crossprod(X, y))

objective <- function(beta) {
  (sum(exp(X %*% beta)) - beta %*% Xty) / nrow(X)
}

gradient <- function(beta) {
  (colSums(drop(exp(X %*% beta)) * X) - Xty) / nrow(X)
}
```

. . .

Gradient descent and Newton method implementations can be found in
[`debugging.R`](R/debugging.R).

```{r source-debugging-file, cache=FALSE}
source(here::here("R/debugging.R"))
```

## Testing

```{r run-gd}
gradient_descent(c(0, 0), objective, gradient, t0 = 1, epsilon = 1e-8)
```

. . .

```{r run-glm}
glm(y ~ x, family = "poisson")
```

### Traceback

- Sometimes enough to simply look at the call stack

## Entering Debug Mode

Two common ways to enter debug mode:

- `browser()`: Stops execution and enters debug mode
- Set a breakpoint in RStudio.

. . .

:::: {.columns}

::: {.column width="47%"}

### `browser()`

- Can be placed anywhere in the code
- Stops execution and enters debug mode

:::

::: {.column width="47%"}

### RStudio Breakpoints

- Visual breakpoints
- Easy to set and remove (click in the margin)
- No need to modify the code
- But cannot be conditionally set
- Sometimes won't work

:::

::::

## Buggy Newton Method

```{r def-hessian}
hessian <- function(beta) {
  (crossprod(X, drop(exp(X %*% beta)) * X)) / nrow(X)
}
```

```{r run-newton, error=TRUE, linewidth = 80}
newton_method(c(0, 0), objective, gradient, hessian)
```

## Exercise: Debugging `newton_method()`

- Download and open [`debugging.R`](R/debugging.R) in RStudio.
- Create another script and define `objective()`, `gradient()`, and `hessian()`
  by copying from these slides.
- Source `debugging.R` and test that `gradient_descent()` works. Now try
  `newton_method()`. Oh no, there's an error!
- Insert a breakpoint before the `while` loop and inspect the values of
  `objective(x_new)`, `values`, `alpha`, `beta` and `grad_d_prod` from within
  the browser.
- Explain and fix the bug. Remove the breakpoint.
- Source the fixed code and try calling `newton_method()`. What happens?
- Debug the code again, using breakpoints or `browser()`. Finally verify that
  `newton_method()` works.

## Debugging C++ Code (Rcpp)

- Unfortunately **not** easy.
- General problem is that C++ code is compiled, so what you see in C++ is not
  necessarily what is executed.
- We won't cover it here, but it **is** possible: see
  [these notes](https://github.com/wch/r-debug/blob/master/debugging-r.md) for
  instance.
