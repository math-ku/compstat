---
title: "Measuring and Improving Performance"
---

{{< include _common.qmd >}}

```{r setup, include=FALSE}
source(here::here("R", "kernel.R"), keep.source = TRUE)
source(here::here("R", "gauss.R"), keep.source = TRUE)

phipsi <- read.table(here::here("data", "phipsi.tsv"), header = TRUE)
phipsi[, c("phi", "psi")] <- pi * phipsi[, c("phi", "psi")] / 180
```

## Today's Agenda

### Profiling

Identifying bottlenecks in code

. . .

### Benchmarking

Comparing performance of implementations

. . .

### Improving Performance

Writing efficient code

## Two Types of Performance

### Speed

How long does it take to run?

. . .

### Memory

How much memory space does it use?

. . .

### At Odds

Often, improving one worsens the other.

. . .

### In this Course

We will focus on **speed**, not **memory**.

## Do You Even Need to Optimize?

Before starting to think about improving performance---do you even need to do
so?

. . .

### The Root of All Evil

\medskip

> We _should_ forget about small efficiencies, say about 97% of the time:
> premature optimization is the root of all evil. Yet we should not pass up our
> opportunities in that critical 3%.
>
> \medskip
> _—Donald Knuth_

. . .

\medskip

Maybe your code is already fast enough (for your use case)?

\medskip

. . .

Often, improving performance comes at the cost of code readability.


## Profiling

But if your code \alert{is} too slow, then it's time to profile it.

. . .

\medskip

A profiler quantifies how much time each part of your code takes to run. There
are two main types of profiling:

. . .

:::: {.columns}

::: {.column width="47%"}

### Types of Profiling {.example}

**Instrumentation-based profiling** inserts code to measure time taken by
functions.

. . .

\medskip

**Sampling-based profiling** periodically samples the call stack to see what
functions are running.

\pause\medskip

This is what R's profilers do.

:::

::: {.column width="47%"}

### Outputs of Profilers {.alert}

Profilers record both time and memory usage.

:::

::::

## Profiling in R

The R package
[profvis](https://CRAN.R-project.org/package=profvis)
provides useful visualization tools. Can also be activated through the
RStudio/Positron IDE.

```{r load_profvis}
library(profvis)
```

. . .

### Simple to Use

1. Source the code you want to profile using `source()`.\pause
2. Either run `profvis()` on the expression you want to profile or in R studio,
   `Profile -> Start Profiling`, run your code, and then `Profile -> `Stop
   Profiling`.

. . .

The result is an interactive webpage (tab in RStudio).

```{r source_profvis}
#| eval: false
source("<your-file>.R")
profvis(your_function())
```

## Example

Let's profile the implementation of the kernel density estimator from the last
lecture.

```{r}
# In file R/kernel.R
kern_dens <- function(x, h, m = 512) {
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)

  for (i in seq_along(xx)) {
    for (j in seq_along(x)) {
      y[i] <- y[i] + exp(-(xx[i] - x[j])^2 / (2 * h^2))
    }
  }

  y <- y / (sqrt(2 * pi) * h * length(x))

  list(x = xx, y = y)
}
```

## Example

Now let's run the profiler.

. . .

```{r}
#| eval: false
source(here::here("R", "kernel.R"))

x <- rnorm(1e5)

profvis(kern_dens(x, 0.2))
```

. . .

We could have also just placed the code inside the same source file, but this
way we can keep the code clean.

##

![](../images/profvis-kern.png)

\pdfpcnote{
  Ask them to identify the bottleneck.

  Say we will fix this now.
}

## A First Optimization

The bottleneck is the nested loop, which imposes considerable overhead in R.

\pause\medskip

Fixing this is easy! We can \alert{vectorize} the inner loop.

. . .


```{r}
#| eval: false
# Old (Nested Loop)
kern_dens_vec <- function(x, h, m = 512) {
  # ...
  for (i in seq_along(xx)) {
    for (j in seq_along(x)) {
      y[i] <- y[i] + exp(-(xx[i] - x[j])^2 / (2 * h^2))
    }
  }
  # ...
}
```

## A First Optimization

The bottleneck is the nested loop, which imposes considerable overhead in R.

Fixing this is easy! We can \alert{vectorize} the inner loop.

```{r}
#| eval: false
# New (vectorized)
kern_dens_vec <- function(x, h, m = 512) {
  # ...

  for (i in seq_along(xx)) {
    y[i] <- sum(exp(-(xx[i] - x)^2 / (2 * h^2)))
  }

  # ...
}
```

. . .

How much faster is this? We'll \alert{benchmark} this soon.

```{r}
#| echo: false
kern_dens_vec <- function(x, h, m = 512) {
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)

  for (i in seq_along(xx)) {
    y[i] <- sum(exp(-(xx[i] - x)^2 / (2 * h^2)))
  }

  y <- y / (sqrt(2 * pi) * h * length(x))

  list(x = xx, y = y)
}
```

## Common Pitfalls

### Anonymous Functions

Complicates profiling since you will only see `<Anonymous>` in the output.

. . .

### Resolution

Resolution (sampling frequency) may too low for small pieces of code---but do
you really need to profile them then?

. . .

### Quarto and R Markdown

Running profvis inside Quarto/RMarkdown often does not work well. But, if you
do, using `keep.source = TRUE` in `source()` might help.

# Benchmarking

## Benchmarking

The purpose of benchmarking is to compare the performance of different
implementations of the same task.

. . .

### The bench Package

We use the R package
[bench](https://cran.r-project.org/package=bench) for
benchmarking.

```{r}
library(bench)
```

. . .

### `bench::mark()`

The main function of the package: a high-precision timer that adaptively chooses
the number of iterations to get accurate results.

. . .

Also checks results for correctness, unless `check = FALSE`.

## A First, Simple Benchmark

```{r}
x <- runif(100)

sqrt_bench <- bench::mark(
  sqrt(x),
  x^0.5
)

sqrt_bench
```

## `plot.bench_mark()`


```{r bee-bench}
#| fig-width: 5.5
#| fig-cap: A beeswarm plot of the benchmark results.
plot(sqrt_bench)
```

. . .

The
[ggbeeswarm](https://CRAN.R-project.org/package=ggbeeswarm)
package is necessary for default plot behavior.


## Parameterized Benchmarking

Achieve parameterized benchmarking with `bench::press()`, that runs functions
across outer product of its initial arguments.

. . .

```{r dens-bench}
#| message: false
#| warning: false
dens_bench <- bench::press(
  n = 2^(6:9),
  {
    x <- rnorm(n)
    bench::mark(
      base = density(x, 0.2),
      loop = kern_dens(x, 0.2),
      vectorized = kern_dens_vec(x, 0.2),
      check = FALSE # Why? Recall last lecture!
    )
  }
)
```

## Bench Press Results

```{r head-bench}
head(dens_bench, 6)
```

##

```{r default-press-plot}
#| fig-cap: Default plot method for `bench::press()` results, here showing
#|  the performance of three different implementations of a kernel density
#|  estimator.
#| fig-width: 5.5
#| fig-height: 2.6
plot(dens_bench)
```

##

```{r custom-bench-plot-code}
#| ref-label: "custom-bench-plot-code"
#| fig-height: 1.8
#| fig-width: 3.4
#| fig-cap: Custom plot of benchmark results for the three different
#|   implementations.
mutate(dens_bench, method = as.character(expression)) |>
  ggplot(aes(n, median, color = method)) +
  geom_point() +
  geom_line() +
  labs(y = "time (µs)")
```

\pdfpcnote{
  Mention the difference in how performance scales with n.
}

## Notes About Benchmarking

### Don't Relativize Too Much

Look at absolute values too: does the difference matter (for your use case)?

. . .

### Background Tasks

Your computer may be doing something else at the same time.

. . .

### Hardware

Hardware matters: different computers may give different results.

\pdfpcnote{
  Mention that some students had benchmarks running before
  they went into sleep mode.
}

# Improving Performance

## Improving Performance

We could divide the strategies for optimizing code into a **general** and a
**R-specific** section.

. . .

:::: {.columns}

::: {.column width="47%"}

### General Strategies

Strategies that apply to **every** computer language, such as

- avoiding copies,\pause
- storing data wisely,\pause and
- parallelizing.

:::

. . .

::: {.column width="47%"}

### R-Specific Tricks

Strategies that apply selectively to the R language, such as calling

- vectorized (compiled) functions, or\pause
- specialized functions.

:::

::::

. . .

### Context-Specific Tricks

Strategies that are specific to the problem at hand, such as **binning** (later
this lecture).

## R Is Slow ...

... when used like a low-level language.

\pause\medskip

R is an **interpreted** (as opposed to _compiled_) language. You have the
convenience of never having to wait around for something to compile, but pay the
price when you need a piece of code to be fast.


\pause\medskip

It was written mainly for specifying statistical models (not for developing new
numerical methods).

\pause\medskip

It is suitable for high-level programming where most low-level computations are
implemented in a compiled language (e.g. `lm()` and `qr()`.)

## R Is Fast ...

... when most computations are carried out by calls to compiled code.

. . .

```{r}
x <- rnorm(1e4)
bench_res <- bench::mark(
  loop = {
    y <- numeric(length(x))
    for (i in seq_along(x)) {
      y[i] <- 10 * x[i]
    }
    y
  },
  vectorized = 10 * x
)
```

##

```{r bench-plot}
#| fig-width: 5
#| fig-cap: Benchmark results for a loop vs. a vectorized computation
plot(bench_res)
```

## Vectorization

Vectorization means rewriting code to operate on entire vectors at once, instead
of looping over elements. (E.g. `mean()` instead of a `for` loop.)

. . .

\medskip

The term is misleading. Most "vectorized" code also involves a loop, but one
that is typically written in C, C++, or Fortran.

## Beware of Loops in Disguise

Just because you ran a vectorized function, it doesn't make it fast.

. . .

```{r}
loop_bench <- bench::mark(
  sapply = sapply(x, function(x_i) 10 * x_i),
  loop = {
    y <- numeric(length(x))

    for (i in seq_along(x)) {
      y[i] <- 10 * x[i]
    }

    y
  }
)
```

---

```{r}
#| fig-width: 5
#| fig-height: 2
#| fig-cap: The loop is slightly faster than the vectorized `sapply()`.
#| echo: false
plot(loop_bench)
```

## Binning in Density Estimation

The line profiler revealed that most time is spent on the kernel evaluation, but
we cannot optimize the kernel further.

\medskip\pause

But we can use \alert{binning}: create $B$ bins and evaluate the kernel and
replace
$$
  \hat{f}(x) = \frac{1}{n h} \sum_{i=1}^n K\left( \frac{x - x_i}{h} \right)
$$
with
$$
  \hat{f}(x) = \frac{1}{n h} \sum_{j=1}^B n_j K\left( \frac{x - c_j}{h} \right)
$$
where $c_j$ is the center of the $j$th bin and $n_j$ is the number of data
points in the $j$th bin.

\medskip\pause

Turns complexity from $O(nm)$ to $O(n) + O(mB)$.

## Binning Procedure

1. Determine the range of the data and divide it into equal-sized bins.\pause
2. Count the number of data points in each bin.\pause
3. For each bin, compute the kernel density estimate using the bin count and the
   kernel function.\pause
4. For a new data point, find the bin it belongs to and use the pre-computed
   kernel density estimate for that bin.

. . .

\medskip


It's an example of context-specific optimization.

. . .

### Caution

If $n < B$, then binning will not help^[But do you need to optimize for this
scenario?].

## Implementation

A key to the implementation is this function, which loops over the data, for
each point checking which bin center is closest.

```{r}
kern_bin <- function(x, l, u, B) {
  w <- numeric(B)
  delta <- (u - l) / (B - 1)

  for (j in seq_along(x)) {
    i <- floor((x[j] - l) / delta + 0.5) + 1
    w[i] <- w[i] + 1
  }

  w / sum(w)
}
```

## Full Binning Implementation

```{r}
kern_dens_bin <- function(x, h, m = 512) {
  rg <- range(x) + c(-3 * h, 3 * h)
  xx <- seq(rg[1], rg[2], length.out = m)

  w <- kern_bin(x, rg[1], rg[2], m)

  kerneval <- exp(-(xx - xx[1])^2 / (2 * h^2)) / (sqrt(2 * pi) * h)
  kerndif <- toeplitz(kerneval)
  y <- colSums(w * kerndif)

  list(x = xx, y = y, h = h)
}
```

The `kern_dens_bin()` function computes bin weights using `kern_bin()` with grid
points as bin centers.

##

```{r micro3}
#| echo: false
#| fig-width: 5.5
#| fig-cap: The relative benefit of binning increases with the size of the data.
#| fig-height: 3
res2 <- bench::press(
  n = 2^(5:13),
  {
    h <- 0.2
    x <- rnorm(n)
    bench::mark(
      base = density(x, h),
      loop = kern_dens(x, h),
      vectorized = kern_dens_vec(x, h),
      binning = kern_dens_bin(x, h),
      check = FALSE
    )
  }
)

mutate(
  res2,
  expr = as.character(expression),
  median = as.numeric(median)
) |>
  ggplot(aes(n, median, color = expr)) +
  geom_point() +
  geom_line() +
  scale_y_log10() +
  labs(y = "time (µs)")
```


## Testing

As always, we should test our code to ensure it works as expected.

. . .

```{r plot-kern-dens-benchmark}
#| fig-width: 3.5
#| echo: false
#| fig-cap: The standard density estimator as a filled area and
#|   the binning estimate as a black line.
set.seed(123)
x <- rnorm(1e4) + rnorm(1e4, -3, 0.7)

y1 <- kern_dens(x, 0.2)
y2 <- kern_dens_bin(x, 0.2)

df1 <- tibble(
  x = y1$x,
  y = y1$y,
  method = "standard"
)

df2 <- tibble(
  x = y2$x,
  y = y2$y,
  method = "binning"
)

ggplot() +
  geom_area(aes(x, y), data = df2, fill = "blue", alpha = 0.4) +
  geom_line(aes(x = x, y = y), data = df1)
```

##

```{r test-kern-dens-bench}
#| fig-width: 5.5
#| echo: false
#| fig-cap: Absolute errors due to bining decrease with increasing length of
#|   data sequence.
x0 <- kern_dens(x, 0.2)$x
df <- data.frame(
  x = rep(x0, 3),
  diff = c(
    kern_dens(x[1:128], 0.2)$y - kern_dens_bin(x[1:128], 0.2)$y,
    kern_dens(x[1:1024], 0.2)$y - kern_dens_bin(x[1:1024], 0.2)$y,
    kern_dens(x, 0.2)$y - kern_dens_bin(x, 0.2)$y
  ),
  n = factor(rep(c(128, 1024, 8192), each = length(x0)))
)

ggplot(df, aes(x, diff)) +
  facet_wrap(~n) +
  geom_hline(yintercept = 0, col = "grey80") +
  geom_line() +
  ylab("Difference")
```

## Line Profiling

The `kern_dens_bin()` function is so much faster for long sequences that to get
good profiling results we use a 512 times longer data sequence.

```{r eval = FALSE}
x <- rnorm(2^22)
source(here::here("R", "kernel.R"))
profvis(kern_dens_bin(x, 0.2))
```

##

![](../images/profvis-kern-bin.png)

\pdfpcnote{
  The bottleneck is now the loop in `kern_bin()`.
}


## Avoiding Copies

### Copy-on-Write (Modify)

**Recall:** R passes objects by reference, but when an object is
\alert{modified} a copy is created.

\pause\medskip

### Examples {.example}

- Accessing a column of a matrix.\pause
- Growing vectors (`c()`) and matrices (`rbind()`, `cbind()`).

. . .

```{r}
x <- rnorm(100)
x <- c(x, 4) # 101 values are allocated
```

## Memory

### Memory in R

In R, everything is typically loaded into memory.

### Garbage Collection

R includes a garbage collector, which intermittently releases unused blocks
in memory.

### Trade-Offs

Storing intermediate objects that are used multiple times will boost performance
at the cost of additional memory storage.

## Storage Mode

:::: {.columns}

::: {.column width="47%"}

R stores matrices in \alert{column-major order}.

\pause\medskip

When you access a column of a matrix, you are accessing a \alert{contiguous}
block of memory.

\pause\medskip

Some operations are faster with column-major order and others are faster with
row-major order.


:::

::: {.column width="47%"}

### Computing Matrix-Vector Products

```{r}
matvecmul_v1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}
```

:::

::::



##

```{r}
#| echo: false
#| fig-width: 5
#| fig-cap: Benchmark results for three different implementations of
#|   matrix-vector multiplication.
n <- 1e3
p <- 1e1

x <- matrix(rnorm(n * p), n)
y <- matrix(rnorm(p), p, 1)

f1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}

f2 <- function(x, y) {
  n <- NROW(x)
  x_t <- t(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- x_t[, i] %*% y
  }

  z
}

f3 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(NCOL(x))) {
    z <- z + x[, i] * y[i]
  }

  z
}

bench::mark(f1(x, y), f2(x, y), f3(x, y)) |>
  plot()
```

## Concurrency

Most processors have multiple cores.

\medskip\pause

But unless instructed otherwise, only a single core is going to be used.

\medskip\pause

The computer doesn't automatically know that your computations are safe to do
in parallel.

## Embarrassingly Parallel Tasks

Tasks that easily separate into independent subtasks.

\pause\medskip

### Examples {.example}

- Summing a vector (or matrix): `sum()`\pause
- Linear algebra operations: `%*%` (`crossprod()`)\pause
- Running iterations of a simulation\pause
- Cross-validation

## The foreach Package

:::: {.columns}

::: {.column width="47%"}

```{r foreach-load}
#| warning: true
#| message: true
library(foreach)
```

```{r foreach-sqrt}
#| eval: false
foreach(i = seq_len(3)) %dopar%
  {
    sqrt(i)
  }
```

:::

. . .

::: {.column width="47%"}

```{r}
#| echo: false
#| ref-label: "foreach-sqrt"
```


:::

::::

\pause\medskip

### Notes {.alert}

- Returns a list (so not really a for loop).\pause
- Nothing is actually parallel yet!\pause
- First, we need to register a **backend**.

## Backends to foreach

Multiple backends, installed separately (**doParallel**, **doMC**, **doFuture**)

\pause\medskip

Load and **register** one before using foreach.

```{r doparallel}
#| message: true
library(doParallel)
cl <- makeCluster(2) # 2 is the number of threads requested
registerDoParallel(cl)

foreach(i = seq_len(3)) %dopar%
  {
    cat("Hello from process", Sys.getpid(), "\n")
  }
```

## Combining Results

`foreach()` always returns a list.

\medskip\pause

If you want to reduce your result, use either the `.combine` argument or
manually reduce the resulting list.

. . .

### `.combine`

```{r}
x <- c(4, 1, 1e2, 2)

foreach(i = seq_len(4), .combine = c) %dopar%
  {
    log(x[[i]])
  }
```


## Futures

A future represents a value that may be available later on.

\medskip\pause

Sometimes called \alert{promises}: "I promise to give you the result later."

. . .

:::: {.columns}

::: {.column width="47%"}

### Without Futures {.alert}

```{r}
v <- {
  cat("Hello world!\n")
  3.14
}
v
```

:::

. . .

::: {.column width="47%"}

### With Futures {.example}

```{r}
library(future)
v %<-%
  {
    cat("Hello world!\n")
    3.14
  }
v
```

:::

::::

## Futures Enable Parallelization

A new \alert{thread} is created for each future.

\medskip\pause

- Other work can be done in the meantime on main thread.
- Once the value is needed, hopefully it is already (or best: just-in-time)
  available.

```{r}
#| eval: false
plan(multicore) # Not on Windows or RStudio!

z %<-%
  {
    # Peform some expensive computation
  }

# Perform other work here ...

z # This line blocks until z is available
```

## Caveats

### Realistic Expectations

In practice, twice as many cores $\neq$ twice as fast (in practice).


. . .

### Overhead

Parallelization comes with overhead (starting threads, communication).


. . .

### Thread Safety

Some functions are not thread safe (e.g. random number generation).

. . .

### Redundancies

Parallelizing a task that is already parallelized may not help and may even
\alert{hurt} performance.


# Exercises

## Exercises

### Exercise 1

Benchmark `gauss()` against `dnorm()`; plot and compare the results. Before
starting: which do you think will be faster?

```{r}
gauss <- function(x, h = 1) {
  exp(-x^2 / (2 * h^2)) / (h * sqrt(2 * pi))
}
```

. . .

### Exercise 2

Profile `gauss()`. Where is the bottleneck? Can you improve the performance?

. . .

### Exercise 3

Write a parallelized version of the `gauss()` function using the `foreach`
package. Your function should take a vector and devide the work across multiple
cores.

\medskip\pause

Benchmark your implementation against the original `gauss()` function.


## Summary

- First find bottlenecks through profiling\pause
- Benchmark different implementations and use existing solutions\pause
- Vectorize and use domain-specific knowledge to improve performance.

. . .

### Keep in Mind

- Only optimize when it's needed: profile first\pause
- Keep readability in mind: performant code can be hard to read.\pause
- Write tests: performance improvements can introduce bugs.
