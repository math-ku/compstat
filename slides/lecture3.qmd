---
title: "Measuring and Improving Performance"
---

{{< include _common.qmd >}}

```{r setup, include=FALSE}
source(here::here("R", "kernel.R"), keep.source = TRUE)
source(here::here("R", "gauss.R"), keep.source = TRUE)

phipsi <- read.table(here::here("data", "phipsi.tsv"), header = TRUE)
phipsi[, c("phi", "psi")] <- pi * phipsi[, c("phi", "psi")] / 180
```

## Today's Agenda

### Profiling

Identifying bottlenecks in code

. . .

### Benchmarking

Comparing performance of implementations

. . .

### Improving Performance

Writing efficient code

## Two Types of Performance

### Speed

How long does it take to run?

. . .

### Memory

How much memory space does it use?

. . .

### At Odds

Often, improving one worsens the other.

. . .

### In this Course

We will focus on **speed**, not **memory**.

## Do You Even Need to Optimize?

Before starting to think about improving performance---do you
even need to do so?

. . .

### The Root of All Evil

\medskip

> We _should_ forget about small efficiencies, say about 97% of the time:
> premature optimization is the root of all evil. Yet we should not pass up our
> opportunities in that critical 3%.
>
> \medskip
> _—Donald Knuth_

. . .

\medskip

Maybe your code is already fast enough (for your use case)?

\medskip

. . .

Often, improving performance comes at the cost of code readability.


## Profiling

But if your code \alert{is} too slow, then it's time to profile it.

. . .

\medskip

A profiler quantifies how much time each part of your code takes to run.
There are two main types of profiling:

. . .

:::: {.columns}

::: {.column width="47%"}

### Types of Profiling {.example}

**Instrumentation-based profiling** inserts code to measure time taken by
functions.

. . .

\medskip

**Sampling-based profiling** periodically samples the call stack to see what
functions are running.

\pause\medskip

This is what R's profilers do.

:::

::: {.column width="47%"}

### Outputs of Profilers

Profilers record both time and memory usage.

:::

::::

## Profiling in R

The R package [profvis](https://CRAN.R-project.org/package=profvis) provides
useful visualization tools. Can also be called activated through the RStudio/Positron
IDE.

```{r load_profvis}
library(profvis)
```

. . .

### Simple to Use

1. Source the code you want to profile using `source()`.\pause
2. Either run `profvis()` on the expression you want to profile or 
   in R studio, `Profile -> Start Profiling`, run your code, and then `Profile
   -> `Stop Profiling`.

. . .

The result is an interactive webpage (tab in RStudio).

```{r source_profvis}
#| eval: false
source("<your-file>.R")
profvis(your_function())
```

## Example

Let's profile the implementation of the kernel density estimator
from the last lecture.

```{r}
# In file R/kernel.R
kern_dens <- function(x, h, m = 512) {
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)

  for (i in seq_along(xx)) {
    for (j in seq_along(x)) {
      y[i] <- y[i] + exp(-(xx[i] - x[j])^2 / (2 * h^2))
    }
  }

  y <- y / (sqrt(2 * pi) * h * length(x))

  list(x = xx, y = y)
}
```

## Example 

Now let's run the profiler.

. . .

```{r}
#| eval: false
source(here::here("R", "kernel.R"))

x <- rnorm(1e5)

profvis(kern_dens(x, 0.2))
```

. . .

We could have also just placed the code inside the same source file, but
this way we can keep the code clean.

##

![](../images/profvis-kern.png)

\pdfpcnote{
  Ask them to identify the bottleneck.

  Say we will fix this now.
}

## A First Optimization

The bottleneck is the nested loop, which imposes considerable overhead
in R.

\pause\medskip

Fixing this is easy! We can \alert{vectorize} the inner loop.

. . .

### Old (Nested Loop)

```{r}
#| eval: false
kern_dens_vec <- function(x, h, m = 512) {
  # ...
  for (i in seq_along(xx)) {
    for (j in seq_along(x)) {
      y[i] <- y[i] + exp(-(xx[i] - x[j])^2 / (2 * h^2))
    }
  }
  # ...
}
```

## A First Optimization

The bottleneck is the nested loop, which imposes considerable overhead
in R.

Fixing this is easy! We can \alert{vectorize} the inner loop.

### New (Vectorized)

```{r}
#| eval: false
kern_dens_vec <- function(x, h, m = 512) {
  # ...

  for (i in seq_along(xx)) {
    y[i] <- sum(exp(-(xx[i] - x)^2 / (2 * h^2)))
  }

  # ...
}
```

. . .

How much faster is this? We'll \alert{benchmark} this soon.

```{r}
#| echo: false
kern_dens_vec <- function(x, h, m = 512) {
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)

  for (i in seq_along(xx)) {
    y[i] <- sum(exp(-(xx[i] - x)^2 / (2 * h^2)))
  }

  y <- y / (sqrt(2 * pi) * h * length(x))

  list(x = xx, y = y)
}
```

## Common Pitfalls

### Anonymous Functions

Complicates profiling since you will only see `<Anonymous>` in the output.

. . .

### Resolution

Resolution (sampling frequency) may too low for small pieces of code---but do
you really need to profile them then?

. . .

### Quarto and R Markdown

Running profvis inside Quarto/RMarkdown often does not work well. But,
if you do, using `keep.source = TRUE` in `source()` might help.

# Benchmarking

## Benchmarking

The purpose of benchmarking is to compare the performance of different
implementations of the same task.

. . .

### The bench Package

We use the R package [bench](https://cran.r-project.org/web/package=bench) for
benchmarking.

```{r}
library(bench)
```

. . .

### `mark()` (`bench::mark()`)

The main function of the package: a high-precision timer that adaptively chooses
the number of iterations to get accurate results.

. . .

Also checks results for correctness, unless `check = FALSE`.

## A First, Simple Benchmark

```{r}
x <- runif(100)

sqrt_bench <- bench::mark(
  sqrt(x),
  x^0.5
)

sqrt_bench
```

## `plot.bench_mark()`

[ggbeeswarm](https://CRAN.R-project.org/package=ggbeeswarm) necessary for
default plot behavior.

```{r bee-bench}
#| fig-width: 5.5
plot(sqrt_bench)
```


## Parameterized Benchmarking

Achieve parameterized benchmarking with `bench::mark()`, that runs functions
across outer product of its initial arguments.

. . .

```{r dens-bench}
#| message: false
#| warning: false
dens_bench <- bench::press(
  n = 2^(6:9),
  {
    x <- rnorm(n)
    bench::mark(
      base = density(x, 0.2),
      loop = kern_dens(x, 0.2),
      vectorized = kern_dens_vec(x, 0.2),
      check = FALSE # Why? Recall last lecture!
    )
  }
)
```

## Bench Press Results

```{r head-bench}
head(dens_bench, 6)
```

## 

```{r default-press-plot}
#| fig-cap: Default plot method for `bench::press()` results, here showing
#|  the performance of three different implementations of a kernel density
#|  estimator.
#| fig-width: 5.5
#| fig-height: 2.6
plot(dens_bench)
```

## 

```{r custom-bench-plot-code}
#| ref-label: "custom-bench-plot-code"
#| fig-height: 1.8
#| fig-width: 3.4
#| fig-cap: Custom plot of benchmark results for the three different
#|   implementations.
mutate(dens_bench, method = as.character(expression)) |>
  ggplot(aes(n, median, color = method)) +
  geom_point() +
  geom_line() +
  labs(y = "time (µs)")
```

## Notes About Benchmarking

### Don't Relativize Too Much

Look at absolute values too: does the difference matter (for your use case)?

. . .

### Background Tasks

Your computer may be doing something else at the same time.

. . .

### Hardware

Hardware matters: different computers may give different results.

\pdfpcnote{
  Mention that some students had benchmarks running before
  they went into sleep mode.
}

# Improving Performance

## Improving Performance

We could divide the strategies for optimizing code into
a **general** and a **R-specific** section.

. . .

:::: {.columns}

::: {.column width="47%"}

### General Strategies

Strategies that apply to **every** computer language, such
as

- avoiding copies,\pause
- storing data wisely,\pause and
- parallelizing.

:::

. . .

::: {.column width="47%"}

### R-Specific Tricks

Strategies that apply selectively to the R language,
such as

- calling compiled code,\pause and
- calling specialized functions.

:::

::::

. . .

### Context-Specific Tricks

Strategies that are specific to the problem at hand,
such as **binning** (later this lecture).

## R Is Slow ...

... when used like a low-level language.

\pause\medskip

R is an **interpreted** (as opposed to _compiled_) language. You 
have the convenience of never having to wait around for something to
compile, but pay the price when you need a piece of code to be fast.


\pause\medskip

It was written mainly for specifying statistical models (not for developing
new numerical methods).

\pause\medskip

It is suitable for high-level programming where most low-level computations
are implemented in a compiled language (e.g. `lm()` and `qr()`.)

## R Is Fast ...

... when most computations are carried out by calls to compiled code.

. . .

```{r}
x <- rnorm(1e4)
bench_res <- bench::mark(
  loop = {
    y <- numeric(length(x))
    for (i in seq_along(x)) {
      y[i] <- 10 * x[i]
    }
    y
  },
  vectorized = 10 * x
)
```

## 

```{r bench-plot}
#| fig-width: 5
#| fig-cap: Benchmark results for a loop vs. a vectorized computation
plot(bench_res)
```

## Vectorization

Vectorization means rewriting code to operate on entire vectors at once,
instead of looping over elements.

. . .

\medskip

But the term is misleading, since most "vectorized" code involves a loop too.
But these loops are typically written in C, C++, or Fortran, which makes
them fast.

## Beware of Loops in Disguise

Just because you ran a vectorized function, it does not mean that it is fast.

. . .

```{r}
loop_bench <- bench::mark(
  sapply = sapply(x, function(x_i) 10 * x_i),
  loop = {
    y <- numeric(length(x))

    for (i in seq_along(x)) {
      y[i] <- 10 * x[i]
    }

    y
  }
)
```

---

```{r}
#| fig-width: 5
#| fig-height: 2
#| fig-cap: The loop is slightly faster than the 'vectorized' apply function.
#| echo: false
plot(loop_bench)
```

## Binning in Density Estimation

The line profiler revealed that most time is spent on the kernel evaluation, but
we cannot optimize the kernel further.

\medskip\pause

But we can use \alert{binning}: create $B$ bins and evaluate the kernel and replace
$$
  \hat{f}(x) = \frac{1}{n h} \sum_{i=1}^n K\left( \frac{x - x_i}{h} \right)
$$
with
$$
  \hat{f}(x) = \frac{1}{n h} \sum_{j=1}^B n_j K\left( \frac{x - c_j}{h} \right)
$$
where $c_j$ is the center of the $j$th bin and $n_j$ is the number of data
points in the $j$th bin.

\medskip\pause

Turns complexity from $O(nm)$ to $O(n) + O(mB)$.

## Binning Procedure

1. Determine the range of the data and divide it into equal-sized bins.\pause
2. Count the number of data points in each bin.\pause
3. For each bin, compute the kernel density estimate using the bin count and the
   kernel function.\pause
4. For a new data point, find the bin it belongs to and use the pre-computed
   kernel density estimate for that bin.

. . .

\medskip


It's an example of context-specific optimization.

. . .

### Caution

If $n < B$, then binning will **not** help.

## Implementation

A key to the implementation is this function, which loops over the data, for each point
checking which bin center is closest.

```{r}
kern_bin <- function(x, l, u, B) {
  w <- numeric(B)
  delta <- (u - l) / (B - 1)

  for (j in seq_along(x)) {
    i <- floor((x[j] - l) / delta + 0.5) + 1
    w[i] <- w[i] + 1
  }

  w / sum(w)
}
```

## Full Binning Implementation

```{r}
kern_dens_bin <- function(x, h, m = 512) {
  rg <- range(x) + c(-3 * h, 3 * h)
  xx <- seq(rg[1], rg[2], length.out = m)

  w <- kern_bin(x, rg[1], rg[2], m)

  kerneval <- exp(-(xx - xx[1])^2 / (2 * h^2)) / (sqrt(2 * pi) * h)
  kerndif <- toeplitz(kerneval)
  y <- colSums(w * kerndif)

  list(x = xx, y = y, h = h)
}
```

The `kern_dens_bin()` function computes bin
weights using `kern_bin()` with grid points as bin centers.

## 

```{r micro3}
#| echo: false
#| fig-width: 5.5
#| fig-cap: The relative benefit of binning increases with the size of the data.
#| fig-height: 3
res2 <- bench::press(
  n = 2^(5:13),
  {
    h <- 0.2
    x <- rnorm(n)
    bench::mark(
      base = density(x, h),
      loop = kern_dens(x, h),
      vectorized = kern_dens_vec(x, h),
      binning = kern_dens_bin(x, h),
      check = FALSE
    )
  }
)

mutate(
  res2,
  expr = as.character(expression),
  median = as.numeric(median)
) |>
  ggplot(aes(n, median, color = expr)) +
  geom_point() +
  geom_line() +
  scale_y_log10() +
  labs(y = "time (µs)")
```


## Testing

```{r plot-kern-dens-benchmark}
#| fig-width: 3.5
#| echo: false
#| fig-cap: The standard density estimator as a filled area and
#|   the binning estimate as a black line.
set.seed(123)
x <- rnorm(1e4) + rnorm(1e4, -3, 0.7)

y1 <- kern_dens(x, 0.2)
y2 <- kern_dens_bin(x, 0.2)

df1 <- tibble(
  x = y1$x,
  y = y1$y,
  method = "standard"
)

df2 <- tibble(
  x = y2$x,
  y = y2$y,
  method = "binning"
)

ggplot() +
  geom_area(aes(x, y), data = df2, fill = "blue", alpha = 0.5) +
  geom_line(aes(x = x, y = y), data = df1)
```

## Testing

```{r test-kern-dens-bench}
#| fig-width: 5.5
#| echo: false
x0 <- kern_dens(x, 0.2)$x
plot(
  x0,
  kern_dens(x, 0.2)$y - kern_dens_bin(x, 0.2)$y,
  type = "l",
  ylim = c(-3e-3, 3e-3),
  lwd = 2,
  ylab = "Difference"
)
lines(
  x0,
  kern_dens(x[1:1024], 0.2)$y - kern_dens_bin(x[1:1024], 0.2)$y,
  col = "red",
  lwd = 2
)
lines(
  x0,
  kern_dens(x[1:128], 0.2)$y - kern_dens_bin(x[1:128], 0.2)$y,
  col = "blue",
  lwd = 2
)
```

The absolute errors due to binning are small but increasing with decreasing
length of data sequence. Here $n = 8192$ is black, $n = 1024$ is red and
$n = 128$ is blue.

## Line Profiling

The `kern_dens_bin()` function is so much faster for long sequences that to get
good profiling results we use a 512 times longer data sequence.

```{r eval = FALSE}
x <- rnorm(2^22)
# profvis(kern_dens_bin(x, 0.2))
```

## Vectorization

- Vectorization is the process of replacing loops with vectorized operations.
- These vectorized operations are also loops, but they are written in C instead
  or R.
  - Examples of vectorized functions: `mean()`, `exp()`
  - Examples of non-vectorized functions: `apply()`, `Vectorize()`
- Vectorizing code is often about finding the right function in R.
  - `colSums()` instead of for loop or apply-type of function.

## Exercise on Vectorization

- Vectorize the `kern_bin()` function
- Benchmark the performance of the two functions.
- **Hint:** Use `tabulate()`.

```{r}
kern_bin
```

```{r kern-bin-vec, include = FALSE}
kern_bin_vec <- function(x, lo, hi, m) {
  delta <- (hi - lo) / (m - 1)
  i <- floor((x - lo) / delta + 0.5) + 1
  w <- tabulate(i, nbins = m)
  w / sum(w)
}
```

## Avoiding Copies

### Copy-on-Modify

- In R, objects are passed by reference, but when an object is modified a copy
  is created.
- For instance, when subsetting a matrix, a copy is created. It's not possible
  to access for instance a column by reference.
- Growing vectors (`c()`) and matrices (`rbind()`, `cbind()`) creates copies.

```{r}
x <- rnorm(100)
x <- c(x, 4) # 101 values are allocated
```

## Memory

### Memory in R

In R, everything is typically loaded into memory.

### Garbage Collection

R includes a garbage collector, which intermittently releases unused blocks in
memory.

### Trade-Offs

Storing intermediate objects that are used multiple times will boost performance
at the cost of additional memory storage.

## Exercise

Can you rewrite the following function to avoid creating copies?

```{r}
#| eval: false
matrix_vector_dot
```

## Storage Modes

:::: {.columns}

::: {.column width="47%"}

- In R, matrices are stored in column-major order.
- This is generally language-dependent.
- This means that when you access a column of a matrix, you are accessing a
  contiguous block of memory.
- Some operations are faster with column-major order and others with row-major
  order.

:::

::: {.column width="47%"}

:::

::::

## Exercise

Benchmark the following three implementations of matrix-vector multiplication.

1. Take the inner product of each row with the vector and sum up.
2. First transpose the matrix and then take the inner product.
3. Take the elementwise (Hadamard) product of each column of the matrix and
   vector and sum up. --

### Implementation of First Method

```{r}
matvecmul_v1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}
```

```{r, include = FALSE, cache = TRUE}
n <- 1e3
p <- 1e1

x <- matrix(rnorm(n * p), n)
y <- matrix(rnorm(p), p, 1)

f1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}

f2 <- function(x, y) {
  n <- NROW(x)
  x_t <- t(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- x_t[, i] %*% y
  }

  z
}

f3 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(NCOL(x))) {
    z <- z + x[, i] * y[i]
  }

  z
}

bench::mark(f1(x, y), f2(x, y), f3(x, y))
```

## Concurrency

Modern processors have multiple cores.

\medskip\pause

But unless instructed otherwise, only a single core is going to be used.

\medskip\pause

The computer doesn't automatically know that your computations are safe to do
in parallel.

## Embarassingly Parallel Tasks

Trivial implementation of parallelization

It would be embarassing to miss the opportuity to parallelize the task.

### Examples

- Summing a vector (or matrix): `sum()`
- Linear algebra operations: `%*%` (`crossprod()`)
- Running iterations of a simulation
- Cross-validation

## The foreach Package

:::: {.columns}

::: {.column width="47%"}

```{r foreach-load, message = FALSE, echo = -1}
options(width = 40)
library(foreach)
```

```{r foreach-sqrt}
foreach(i = seq_len(3)) %dopar%
  {
    sqrt(i)
  }
```

:::

::: {.column width="47%"}

### Notes

- Returns a list (so not really a for loop).
- The warning tells us that actually nothing is parallel yet.
- First, we need to register a **backend**.

:::

::::

## Backends

- Multiple backends, installed separately (**doParallel**, **doMC**,
  **doFuture**)
- Load and **register** one before using foreach
- Windows user cannot use forking (which is cheaper)

```{r doparallel, echo = -1, message = FALSE}
options(width = 80)
library(doParallel)

cl <- makeCluster(2) # 2 is the number of threads requested
# cl <- makeForkedCluster(2) # Only on non-Windows

registerDoParallel(cl)
# registerDoParallel(cores = 4) # If not on Windows

res <- foreach(i = seq_len(3)) %dopar%
  {
    cat("Hello from process", Sys.getpid(), "\n")
  }
```

## Combining Results

- `foreach()` always returns a list.
- If you want to reduce your result, use either the `.combine` argument or
  manually reduce the resulting list.

. . .

### `.combine`

```{r}
x <- c(4, 1, 1e2, 2)

foreach(i = seq_len(4), .combine = c) %dopar%
  {
    log(x[[i]])
  }
```

## Exercise

### Part 1

Write a parallelized version of `mean()`. The function should take a vector as
it's first argument and a cluster object as the second argument.

```{r par-mean-intro, eval = FALSE}
par_mean <- function(x) {
  n <- length(x)
  # Your code here
}
```

```{r par-mean, include = FALSE}
par_mean <- function(x) {
  n <- length(x)
  foreach(i = seq_len(n), .combine = sum) %dopar%
    {
      x[[i]] / n
    }
}
```

. . .

### Part 2

Write a parallelized version of `lapply()`. Pass along arguments to the
function.

```{r, include = FALSE}
par_lapply <- function(x, fun, ...) {
  foreach(i = seq_along(x), .combine = sum) %dopar%
    {
      fun(x[[i]], ...)
    }
}

par_lapply(x, sum)
```

## Futures

- An abstraction for a value that may be available at some point in the future.
- Sometimes called promises: "I promise to give you the result later."

. . .

:::: {.columns}

::: {.column width="47%"}

### Without Futures

```{r}
v <- {
  cat("Hello world!\n")
  3.14
}
v
```

:::

::: {.column width="47%"}

### With Futures

```{r}
library(future)
v %<-%
  {
    cat("Hello world!\n")
    3.14
  }
v
```

:::

::::

## Futures Enable Parallelization

- To parallelize a computation, we can use futures.
- A thread is created for each future.
- Other work can be done in the meantime on main thread.
- Once the value is needed, hopefully it is already (or best: just-in-time)
  available.

```{r}
#| eval: false
plan(multisession)

# plan(multicore) # Not on Windows or RStudio!

z %<-%
  {
    # Expensive computation
  }

# Other expensive computations

z # Will block until the value is available
```

## Caveats Regarding Parallelization

- Twice as many cores $\neq$ twice as fast (in practice).
  - Communication overhead
  - Memory overhead
- Thread safety
- Parallelizing functions that are already parallelized internally typicall has
  no (or negative) effect.

## Exercise

Write a program for running ordinary least squares regression in parallel using
the **futures** package.

**Recall:** The OLS estimator is given by $\hat{\beta} = (X^TX)^{-1}X^T y$.

```{r ols-future, include = FALSE}
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
y <- rnorm(n)

xty %<-%
  {
    crossprod(x, y)
  }
xtx <- crossprod(x)
solve(xtx, xty)
```

## Summary

- First find bottlenecks through profiling
- Benchmark different implementations and use existing solutions
- Vectorize and use domain-specific knowledge to improve performance.

. . .

### Keep in Mind

- Only optimize when it's needed: profile first
- Keep readability in mind: performant code can be hard to read.
- Write tests: performance improvements can introduce bugs.

## Exercise

- Profile this implementation of computing a matrix-vector inner product for
  different choices of $n$ and $p$.
- Before starting: where do you think the bottleneck is?

```{r matvec-mul-ex}
matrix_vector_dot <- function(x, y) {
  p <- NCOL(x)

  out <- c()

  for (i in seq_len(p)) {
    xi_y <- t(x[, i]) %*% y
    out <- c(out, xi_y)
  }

  out
}
```

## Exercise

Consider the following implementation of the Gaussian kernel.

```{r gauss-def}
gauss <- function(x, h = 1) {
  exp(-x^2 / (2 * h^2)) / (h * sqrt(2 * pi))
}
```

Benchmark `gauss()` against `dnorm()`; plot and compare the results. Before
starting: which do you think will be faster?

```{r gauss-bench, include = FALSE}
x <- seq(-3, 3, length.out = 10000)

gauss_bench <- bench::mark(
  gauss(x),
  dnorm(x)
)
plot(gauss_bench)
```

## Exercise

- Benchmark `crossprod()` against `%*%` for computing the inner product between
  a matrix and a vector. --

- Parameterize the benchmark by $n$ and $p$.
- Where do you think the difference comes from?

```{r crossprod-bench, include = FALSE, cache = TRUE}
crossprod_bench <- bench::press(
  n = 10^(1:3),
  p = 10^(1:2),
  {
    x <- matrix(rnorm(n * p), n)
    y <- rnorm(n)

    bench::mark(
      t(x) %*% y,
      crossprod(x, y)
    )
  }
)
```
