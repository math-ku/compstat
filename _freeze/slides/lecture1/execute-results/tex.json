{
  "hash": "4bcdd9cd7a03fb141dc4f5272d9badcb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction\"\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n## What is Computational Statistics?\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n- Broad field that can mean different things depending on context.\n- One definitions is that it is the use of computational methods to solve\n  statistical problems, for instance\n  - simulation,\n  - optimization,\n  - numerical integration,\n  - data analysis, and\n  - visualization.\n\n:::\n\n::: {.column width=\"47%\"}\n\n![Running examples: Amino Acid Angles](../images/PhiPsi_creative.jpg){width=70%}\n\n:::\n\n::::\n\n## Histograms\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(\n  phipsi$phi,\n  prob = TRUE,\n  xlab = expression(phi),\n  main = NULL\n)\nrug(phipsi$phi)\n```\n\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/hist1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(\n  phipsi$psi,\n  prob = TRUE,\n  xlab = expression(psi),\n  main = NULL\n)\nrug(phipsi$psi)\n```\n\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/hist2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n::::\n\n## Density Estimation\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlines(\n  density(phipsi$phi),\n  col = \"red\",\n  lwd = 2\n)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/unnamed-chunk-1-1.pdf)\n:::\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlines(\n  density(phipsi$psi),\n  col = \"red\",\n  lwd = 2\n)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/unnamed-chunk-2-1.pdf)\n:::\n:::\n\n\n:::\n\n::::\n\n## Statistical Topics of the Course\n\n### Smoothing\n\n- What does `density()` do?\n- Nonparametric estimators\n- Choosing tuning parameters\n\n. . .\n\n### Simulation\n\n- How do we efficiently simulate from a target distribution?\n- Assessing results from Monte Carlo methods\n- What if we cannot compute the density?\n\n. . .\n\n### Optimization\n\n- How do we compute the MLE?\n- How to we deal with large data sets?\n\n## Computational Topics of the Course\n\n### Implementation\n\n- Writing functions\n- Object-oriented programming\n\n. . .\n\n### Correctness\n\n- Testing\n- Debugging\n\n. . .\n\n### Efficiency\n\n- Profiling\n- Optimizing\n- Benchmarking\n\n## Teaching Staff\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n### Instructor\n\nJohan Larsson, postdoctoral researcher\n\n![Johan](../images/johan.jpg){width=50%}\n\n#### Contact\n\nUse Absalon for course-related questions and email (see Absalon) for personal\nmatters.\n\n:::\n\n::: {.column width=\"47%\"}\n\n### Teaching Assistant\n\nJinyang Liu, PhD student\n\n![Jin](../images/jinyang.jpg){width=50%}\n\n:::\n\n::::\n\n## Assignments\n\n- Main course work of the course\n- Eight assignments, two for each topic\n- Four topics\n  - Smoothing\n  - Univariate simulation\n  - The EM algorithm\n  - Stochastic optimization\n- Pick one assignment per topic.\n\n## Examination\n\n### Presentations\n\n- Present solution to one of the assignments.\n- On weeks 3, 4, 6, and 7 (Thursday afternoon sessions).\n- Groups of 2-3 students\n- Presentation, discussion, and feedback\n- [Register in Absalon](https://absalon.ku.dk/courses/76985/groups#tab-25490)\n  (limited slots assignment)\n- Compulsory but not graded\n- Work-in-progress solutions are fine\n\n. . .\n\n### Oral Examination\n\n- Oral exam, presented indivudally.\n- Prepare four presentations, one for each assignment you picked.\n\n## Schedule\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n### Lectures\n\n- Tuesdays and Thursdays, 10:15–12:00 (Johan)\n\n### Exercise Sessions\n\n- Thursdays, 08:15–10:00 (Jinyang)\n\n### Presentations\n\n- Thursdays, 13:15–15:00 (Johan)\n- Only weeks 3, 4, 6, and 7\n\n:::\n\n::: {.column width=\"47%\"}\n\n### Examination\n\n- November 6 and 7 (8.15-17.30, tentative)\n- Room to be announced\n\n:::\n\n::::\n\n## Course Literature\n\n### Computational Statistics with R\n\nMain textbook for the course, written by Niels Richard Hansen.\n\n- Available online at <https://cswr.nrhstat.org/>\n- Not yet complete, but we only use parts that are.\n- [Companion package](https://github.com/nielsrhansen/CSwR/tree/master/CSwR_package):\n  install with `pak::pak(\"github::nielsrhansen/CSwR/CSwR_package\")`.\n\n. . .\n\n### Advanced R\n\nAuxiliary textbook, written by Hadley Wickham.\n\n- Available online at <https://adv-r.hadley.nz/>\n- Covers more advanced R programming topics.\n- We will use selected chapters.\n\n## Absalon\n\nAccessed at [absalon.ku.dk](https://absalon.ku.dk/).\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n- **Course Material**: Slides, videos, data, groups, and assignments.\n- Actually based on Canvas (but rebranded for UCPH).\n- Download Canvas Student app for your phone.\n- Updated as we go along.\n\n:::\n\n::: {.column width=\"47%\"}\n\n![Absalon](../images/absalon.jpg){width=50%}\n\n:::\n\n::::\n\n## Generative AI\n\n- You can use generative AI to help you with your assignments.\n- But you must understand the results.\n- Can help your learning if used correctly.\n- But also hamper your learning if used inappropriately (too much)\n- Beware of hallucinations!\n\n# Programming in R\n\n## Prerequisite R Knowledge\n\nWe expect knowledge of\n\n- data structures (vectors, lists, data frames),\n- control structures (loops, if-then-else),\n- function calling,\n- interactive and script usage (`source`) of R.\n\nAll of this is covered in chapters 1–5 of\n[Advanced R](https://adv-r.hadley.nz/).\n\nBut you **do not** need to be an experienced programmer.\n\n## Warm-Up Exercises\n\n### Exercise 1\n\nCan you list three ways to access element `a` in this list?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl <- list(a = 1, b = 2)\n```\n:::\n\n\n\n\n. . .\n\n### Exercise 2\n\nWrite a for loop that prints \"even\" if the loop variable is even, \"odd\" if the\nloop variable is odd, and exits if is larger than 10.\n\n# Functions\n\n## Functions in R\n\n- Everything that happens in R is the result of a function call. Even `+`, `[`\n  and `<-` are functions.\n- An R function takes a number of _arguments_, and when a function call is\n  evaluated it computes a _return value_.\n- Functions can return any R object, including functions!\n- Implementations of R functions are collected into source files, which can be\n  organized into packages.\n- The order of your functions in the script does not matter.\n\n## Components of a Function\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n### Arguments\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(x, y) {\n  x + y\n}\n```\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformals(f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$x\n\n\n$y\n```\n\n\n:::\n:::\n\n\n:::\n\n. . .\n\n::: {.column width=\"47%\"}\n\n### Body\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbody(f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{\n    x + y\n}\n```\n\n\n:::\n:::\n\n\n. . .\n\n### Environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nenvironment(f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<environment: R_GlobalEnv>\n```\n\n\n:::\n:::\n\n\n:::\n\n::::\n\n## Naming Functions\n\n### Use Descriptive Names\n\n- Verbs are great.\n- Better long and descriptive than short and cryptic.\n\n. . .\n\n### Naming Convetions\n\n- Avoid `.` in names; it is used for **methods** (upcoming).\n- Use consistent style:\n  - `lowercase`\n  - `snake_case` (tidyverse)\n  - `camelCase`\n  - `UpperCamelCase`\n\n. . .\n\n### Namespace Clashes\n\n- Avoid names of existing functions.\n\n## Example: Counting Zeros\n\nCount data is often modeled using a Poisson distribution. R can simulate count\ndata using the function `rpois()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpois(10, 2) # n = 10 variables from a Poisson(2) distribution\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 2 2 2 4 2 0 1 2 2\n```\n\n\n:::\n:::\n\n\n. . .\n\nThere are two zeros in this sequence.\n\n. . .\n\nLet's write a function that counts the number of zeros: checks for zero\ninflation.\n\n## A First Attempt\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_zeros <- function(x) {\n  n_zeros <- 0\n  for (i in 1:length(x)) {\n    if (x[i] == 0) {\n      n_zeros <- n_zeros + 1\n    }\n  }\n  n_zeros\n}\n\ncount_zeros(c(3, 2, 0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_zeros(c(0, 0, 0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\n## Testing\n\n- Tests that a given input to a function returns what you expect.\n- Thumb of rule: when you find a bug in your function, write a test that fails\n  on it; _then_ fix the function.\n- As you refactor your code (or dependent code changes), your tests will catch\n  these **regressions** for you.\n- Some people even say that writing tests is the first thing you should do.\n- In R, most common solution is to use the **testthat** package.\n- Works best in packages, but is fine for projects too.\n\n## Testing with **testthat**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# In file tests/test_count_zeros.R\ntest_that(\"count_zeros work on various input\", {\n  expect_equal(count_zeros(c(0, 0, 1e-9, 25)), 2)\n  expect_equal(count_zeros(c(-0, 1.1, -2)), 1)\n  expect_equal(count_zeros(c()), 0)\n})\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# testthat::test_dir(\"tests\")\n```\n:::\n\n\n## A Second Attempt\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_zeros <- function(x) {\n  n_zeros <- 0\n  for (i in seq_along(x)) { # <1>\n    if (x[i] == 0) {\n      n_zeros <- n_zeros + 1\n    }\n  }\n  n_zeros\n}\n```\n:::\n\n\n1. Take penguins and then bla.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# testthat::test_dir(\"tests\")\n```\n:::\n\n\n## Debugging\n\n- Sometimes hard to identify the offending piece of code.\n- Helpful to use a debugging tool. R studio comes with a helpful interface for\n  this.\n- We will talk more about debugging in week 5.\n\n## Functional Programming\n\n`sapply()` is what's typically called a _map_, with a function as its second\nargument.\n\n. . .\n\nIt is a feature of R as a functional programming language that it can operate\nwith functions as with any other data structure.\n\n. . .\n\nLet's write our own apply function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_apply <- function(x, fun) {\n  val <- numeric(length(x)) # initialize vector of return values\n  for (i in seq_along(x)) {\n    val[i] <- fun(x[[i]])\n  }\n  val\n}\n```\n:::\n\n\n## Testing Our Apply Function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsapply(1:10, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]     2.718282     7.389056    20.085537    54.598150   148.413159\n [6]   403.428793  1096.633158  2980.957987  8103.083928 22026.465795\n```\n\n\n:::\n\n```{.r .cell-code}\nour_apply(1:10, exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]     2.718282     7.389056    20.085537    54.598150   148.413159\n [6]   403.428793  1096.633158  2980.957987  8103.083928 22026.465795\n```\n\n\n:::\n:::\n\n\n. . .\n\n### Assumptions\n\n`x` is a list, `fun()` takes a single argument, and `fun()` returns a numeric.\n\n## What if `fun()` Needs Additional Arguments?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_apply(1:10, rpois)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in fun(x[[i]]): argument \"lambda\" is missing, with no default\n```\n\n\n:::\n:::\n\n\n. . .\n\n### Anonymous Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_apply(\n  1:10,\n  function(lambda) rpois(1, lambda = 0.9) #<<\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 1 2 0 2 3 1 1 0\n```\n\n\n:::\n:::\n\n\n## `...`\n\nThe `...` (ellipsis) argument passes arguments forward.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_apply <- function(x, fun, ...) {\n  val <- numeric(length(x))\n  for (i in seq_along(x)) {\n    val[i] <- fun(x[[i]], ...)\n  }\n  val\n}\n```\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_apply(1:10, rpois, n = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  0  1  4  3  7  6  8 16  8 12\n```\n\n\n:::\n:::\n\n\n# Benchmarking\n\n## R Is Slow ...\n\n... when used like a low-level language.\n\n- R is an **interpreted** (as opposed to _compiled_) language.\n- It was written mainly for specifying statistical models (not for developing\n  new numerical methods).\n- It is suitable for high-level programming where most low-level computations\n  are implemented in a compiled language (e.g. `lm()` and `qr()`.)\n- It is also quite old.\n\n## R Is Fast ...\n\n... when most computations are carried out by calls to compiled code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(1e4)\n\nbench::mark(\n  {\n    y <- numeric(length(x))\n    for (i in seq_along(x)) {\n      y[i] <- 10 * x[i]\n    }\n    y\n  },\n  10 * x\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 6\n  expression                             min median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>                          <bch:> <bch:>     <dbl> <bch:byt>    <dbl>\n1 { y <- numeric(length(x)) for (i i~ 1.06ms  1.1ms      890.        NA     63.2\n2 10 * x                              2.19us 11.8us    86061.        NA    138. \n```\n\n\n:::\n:::\n\n\n## Loops in Disguise\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbench::mark(\n  sapply(x, function(x_i) 10 * x_i),\n  10 * x\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 6\n  expression                            min  median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>                        <bch:t> <bch:t>     <dbl> <bch:byt>    <dbl>\n1 sapply(x, function(x_i) 10 * x_i)  2.43ms  2.57ms      383.        NA     65.9\n2 10 * x                             2.27us 12.06us    85801.        NA    138. \n```\n\n\n:::\n:::\n\n\n. . .\n\n`apply()` and co. are basically just loops in disguise.\n\n## Vectorization\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_zeros_vec <- function(x) {\n  sum(x == 0)\n}\n```\n:::\n\n\n. . .\n\n- `x == 0` checks if each entry of `x` is 0 and returns a vector of logicals.\n- `sum()` computes and returns the sum of all elements in a vector. Logicals are\n  coerced to integers.\n- In this case the vectorized implementation is cohesive and clear.\n- The vectorized computations are performed by compiled code (C/C++/Fortran),\n  which run faster than pure R code.\n- Writing vectorized code requires a larger knowledge of R functions.\n\n## Development Cycle Sketch\n\n- Is there a good-enough existing implemention for your problem? If yes, then\n  you are done.\n- If not, implement a solution and test it. Does it solve your problem\n  sufficiently well? If yes, then you're done. --\n- If not, then profile (next week!), benchmark, and debug (week 5). Then\n  refactor and optimize.\n\n### The Root of All Evil\n\n> We _should_ forget about small efficiencies, say about 97% of the time:\n> premature optimization is the root of all evil. Yet we should not pass up our\n> opportunities in that critical 3%.\n>\n> _—Donald Knuth_\n\n## Example: Density Estimation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_dens <- function(x, h, m = 512) {\n  rg <- range(x)\n  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)\n  y <- numeric(m)\n\n  for (i in seq_along(xx)) {\n    for (j in seq_along(x)) {\n      #<<\n      y[i] <- y[i] + exp(-(xx[i] - x[j])^2 / (2 * h^2)) #<<\n    } #<<\n  }\n\n  y <- y / (sqrt(2 * pi) * h * length(x))\n\n  list(x = xx, y = y)\n}\n```\n:::\n\n\n## Vectorizing Our Density Estimator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_dens_vec <- function(x, h, m = 512) {\n  rg <- range(x)\n  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)\n  y <- numeric(m)\n  const <- (sqrt(2 * pi) * h * length(x))\n\n  for (i in seq_along(xx)) {\n    y[i] <- sum(exp(-(xx[i] - x)^2 / (2 * h^2))) / const #<<\n  }\n\n  list(x = xx, y = y)\n}\n```\n:::\n\n\n## Benchmarking\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_bench <- bench::mark(\n  kern_dens(phipsi$psi, 0.2),\n  kern_dens_vec(phipsi$psi, 0.2)\n)\n\nsummary(kern_bench)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 6\n  expression                          min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>                     <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 kern_dens(phipsi$psi, 0.2)      13.61ms  13.65ms      72.9        NA      0  \n2 kern_dens_vec(phipsi$psi, 0.2)   1.17ms   1.21ms     812.         NA     26.5\n```\n\n\n:::\n:::\n\n\n## Plot Benchmark Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(kern_bench, type = \"violin\")\n```\n\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/kern-bench-autoplot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Parameterized Benchmarking\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_benchmarks <- bench::press(\n  n = 2^(6:9),\n  m = 2^(5:11),\n  {\n    bench::mark(\n      loop = kern_dens(x[1:n], h = 0.2, m = m),\n      vec = kern_dens_vec(x[1:n], h = 0.2, m = m)\n    )\n  }\n)\n\nhead(kern_benchmarks, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 8\n  expression     n     m      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <dbl> <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 loop          64    32  141.4us  144.4us     6880.        NA     6.09\n2 vec           64    32   22.8us   24.8us    39570.        NA    59.4 \n3 loop         128    32  273.8us  277.7us     3574.        NA     4.05\n```\n\n\n:::\n:::\n\n\n## Plotting Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nmutate(kern_benchmarks, expression = as.character(expression)) |>\n  ggplot(aes(m, median, color = expression)) +\n  geom_point() +\n  geom_line() +\n  facet_grid(cols = vars(n))\n```\n\n::: {.cell-output-display}\n![](lecture1_files/figure-beamer/kern-bench-fig-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Getting Help with R\n\n### Google It\n\nEspecially good for error messages.\n\n. . .\n\n### Generative AI\n\nAlso great for error messages and debugging\n\n**Caution**: You need to understand the results, especially when you ask it to\ncreate something for you.\n\n. . .\n\n### Absalon Discussion Forum\n\nUse the fact that there are twenty other people in the course with exactly the\nsame problem.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}