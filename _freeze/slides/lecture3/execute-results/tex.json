{
  "hash": "88428cdae1361f0f060a7ea6afff4e71",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Measuring and Improving Performance\"\n\nexecute:\n  cache: true\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Today\n\n### Measuring Performance\n\n#### Profiling\n\nIdentifying bottlenecks in code\n\n#### Benchmarking\n\nComparing performance of different implementations\n\n. . .\n\n### Improving Performance\n\nWriting efficient code\n\n## Profiling\n\nA profiler quantifies how much time each part of a function takes up. R uses a\n**sampling** profiler.\n\n. . .\n\n### profvis\n\nThe R package [profvis](https://CRAN.R-project.org/package=profvis) provides\nuseful visualization tools. Can also be called activated through the RStudio\nIDE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(profvis)\n```\n:::\n\n\n. . .\n\n### Remember!\n\n> We _should_ forget about small efficiencies, say about 97% of the time:\n> premature optimization is the root of all evil. Yet we should not pass up our\n> opportunities in that critical 3%.\n>\n> _—Donald Knuth_\n\n## Example\n\nLet's profile the following reimplementation of `gauss()`, which computes the\ndensity of a standard Gaussian distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngauss_step\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction(x, h = 1) {\n  exponent <- x^2 / (2 * h^2)\n  numerator <- exp(-exponent)\n  denominator <- h * sqrt(2 * pi)\n  numerator / denominator\n}\n```\n\n\n:::\n:::\n\n\n## Usage\n\n### Simple to Use\n\n1. Source the code you want to profile using `source()`.\n2. Run `profvis()` on the expression you want to profile. (Or use the RStudio\n   tool.)\n\nThe result is an interactive webpage (opens in tab in RStudio).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here::here(\"R/gauss.R\"), keep.source = TRUE)\nx <- rnorm(1e7)\n# profvis(gauss_step(x))\n```\n:::\n\n\n## Benchmarking Density Estimation\n\nLet's profile our kernel density function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_dens\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction(x, h, m = 512) {\n  rg <- range(x)\n  grid_points <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)\n  y <- numeric(m)\n  for (i in seq_along(grid_points)) {\n    for (j in seq_along(x)) {\n      y[i] <- y[i] + exp(-(grid_points[i] - x[j])^2 / (2 * h^2))\n    }\n  }\n  y <- y / (sqrt(2 * pi) * h * length(x))\n  list(x = grid_points, y = y)\n}\n```\n\n\n:::\n:::\n\n\n## Dissecting Expressions\n\nThe one-liner in the loop did too much (for profiling). `kern_dens_detail()`\nspells out the steps.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction(x, h, m = 512) {\n  rg <- range(x)\n  grid_points <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)\n  y <- numeric(m)\n  for (i in seq_along(grid_points)) {\n    for (j in seq_along(x)) {\n      ## y[i] <- y[i] + exp(- (xx[i] - x[j])^2 / (2 * h^2))\n      z <- grid_points[i] - x[j]\n      z <- z^2\n      z <- z / (2 * h^2)\n      z <- exp(-z)\n      y[i] <- y[i] + z\n    }\n  }\n  y <- y / (sqrt(2 * pi) * h * length(x))\n  list(x = grid_points, y = y)\n}\n```\n\n\n:::\n:::\n\n\n## Line Profiling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here::here(\"R/kernel.R\"), keep.source = TRUE)\n\nx <- rnorm(1e3)\n# profvis(kern_dens_detail(x, 0.2))\n```\n:::\n\n\nThe result from profiling this call is more informative.\n\n\n::: {.cell}\n\n:::\n\n\n## Exercise\n\n- Profile this implementation of computing a matrix-vector inner product for\n  different choices of $n$ and $p$.\n- Before starting: where do you think the bottleneck is?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatrix_vector_dot <- function(x, y) {\n  p <- NCOL(x)\n\n  out <- c()\n\n  for (i in seq_len(p)) {\n    xi_y <- t(x[, i]) %*% y\n    out <- c(out, xi_y)\n  }\n\n  out\n}\n```\n:::\n\n\n## Caveats About Line Profiling\n\n- Anonymous functions complicates profiling; prefer named functions.\n- Resolution (sampling frequency) may too low for small pieces of code (but do\n  you really need to profile them then?)\n\n## Benchmarking\n\nThe purpose of benchmarking is to measure and compare the computational\nresources used by one or more implementations of a computation.\n\n. . .\n\n### Microbenchmarking\n\nBenchmarking small pieces of code.\n\nTypically: 1) find bottleneck through profiling and 2) (micro)benchmark\nalternatives.\n\n### The bench Package\n\nWe use the R package [bench](https://cran.r-project.org/web/package=bench) for\nbenchmarking.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bench)\n```\n:::\n\n\n## `bench::mark()`\n\n- Main function of package\n- High-precision timer\n- Adaptive number of iterations\n- Checks result for correctness (unless `check = FALSE`)\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- runif(100)\n\nsqrt_bench <- bench::mark(\n  sqrt(x),\n  x^0.5\n)\n\nsqrt_bench\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 6\n  expression      min   median `itr/sec` mem_alloc\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>\n1 sqrt(x)    201.98ns 211.99ns  2167939.        NA\n2 x^0.5        1.08us   1.15us   689925.        NA\n# i 1 more variable: `gc/sec` <dbl>\n```\n\n\n:::\n:::\n\n\n## `plot.bench_mark()`\n\n[ggbeeswarm](https://CRAN.R-project.org/package=ggbeeswarm) necessary for\ndefault plot behavior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggbeeswarm)\n\nplot(sqrt_bench)\n```\n\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/bee-bench-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Exercise\n\nConsider the following implementation of the Gaussian kernel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngauss <- function(x, h = 1) {\n  exp(-x^2 / (2 * h^2)) / (h * sqrt(2 * pi))\n}\n```\n:::\n\n\nBenchmark `gauss()` against `dnorm()`; plot and compare the results. Before\nstarting: which do you think will be faster?\n\n\n\n## `bench::press()`\n\nParameterized benchmarking; runs `bench::mark()` across outer product of its\ninitial arguments\n\n. . .\n\n### Benchmarking Density Estimation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndens_bench <- bench::press(\n  n = 2^(5:13),\n  {\n    x <- rnorm(n)\n    bench::mark(\n      base = density(x, 0.2),\n      loop = kern_dens(x, 0.2),\n      vectorized = kern_dens_vec(x, 0.2),\n      check = FALSE\n    )\n  }\n)\n```\n:::\n\n\n[Source for R code](R/kernel.R)\n\n## Bench Press Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(dens_bench, 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 7\n  expression     n      min   median `itr/sec`\n  <bch:expr> <dbl> <bch:tm> <bch:tm>     <dbl>\n1 base          32 113.96us 134.74us     7097.\n2 loop          32   1.48ms   1.73ms      547.\n3 vectorized    32  281.6us 325.74us     2830.\n4 base          64 118.06us    133us     7289.\n5 loop          64   3.21ms   3.36ms      289.\n6 vectorized    64 383.71us 449.53us     2109.\n# i 2 more variables: mem_alloc <bch:byt>,\n#   `gc/sec` <dbl>\n```\n\n\n:::\n:::\n\n\n## Default Plotting Benchpress Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(dens_bench)\n```\n\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/default-press-plot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Custom Plotting\n\nA bit tricky since `bench_mark` objects have custom classes for time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nmutate(\n  dens_bench,\n  expr = as.character(expression),\n  median = as.numeric(median)\n) |>\n  ggplot(aes(n, median, color = expr)) +\n  geom_point() +\n  geom_line() +\n  scale_y_log10() +\n  labs(y = \"time (µs)\")\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/custom-bench-plot-1.pdf)\n:::\n:::\n\n\n## Exercise\n\n- Benchmark `crossprod()` against `%*%` for computing the inner product between\n  a matrix and a vector. --\n\n- Parameterize the benchmark by $n$ and $p$.\n- Where do you think the difference comes from?\n\n\n\n## Notes About Benchmarking\n\n- Look at absolute values too: does the difference matter (for your use case)?\n- Keep use case in mind.\n- Your computer may be doing something else at the same time.\n- Hardware matters: different computers may give different results.\n\n# Improving Performance\n\n## Many Ways\n\n### General Computational Strategies\n\n- Avoiding copies (passing by reference)\n- Storage modes\n- Data structures\n- Parallelization\n\n. . .\n\n### R-Specific Tricks\n\n- Vectorization\n- Using specialized functions\n- Check function help files: arguments matter\n\n. . .\n\n### Context-Specific Tricks\n\n- Density destimation: binning (up next)\n\n## Binning in Density Estimation\n\nThe line profiler revealed that most time is spent on the kernel evaluation, but\nwe cannot optimize the kernel further.\n\n. . .\n\nInstead, we use binning: create $B$ bins and evaluate the kernel and replace\n$$\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^n K\\left( \\frac{x - x_i}{h} \\right)$$\nwith\n$$\\hat{f}(x) = \\frac{1}{n h} \\sum_{j=1}^B n_j K\\left( \\frac{x - c_j}{h} \\right)$$\nwhere $c_j$ is the center of the $j$th bin and $n_j$ is the number of data\npoints in the $j$th bin.\n\n. . .\n\nTurns complexity from $O(nm)$ to $O(n) + O(mB)$.\n\n### Binning Procedure\n\n1. Determine the range of the data and divide it into equal-sized bins.\n2. Count the number of data points in each bin.\n3. For each bin, compute the kernel density estimate using the bin count and the\n   kernel function.\n4. For a new data point, find the bin it belongs to and use the pre-computed\n   kernel density estimate for that bin.\n\nExample of context-specific optimization.\n\n. . .\n\nIf $n < B$, then binning will not help\n\n## Binning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_bin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction(x, l, u, B) {\n  w <- numeric(B)\n  delta <- (u - l) / (B - 1)\n  for (j in seq_along(x)) {\n    i <- floor((x[j] - l) / delta + 0.5) + 1\n    w[i] <- w[i] + 1\n  }\n  w / sum(w)\n}\n```\n\n\n:::\n:::\n\n\nThe `kern_bin()` function is a loop along the data vector, and arithmetic is\nused to determine which bin center is closest to a data point.\n\n. . .\n\nThe `kern_dens_bin()` function (see [the source file](R/kernel.R)) computes bin\nweights using `kern_bin()` with grid points as bin centers.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/micro3-1.pdf)\n:::\n:::\n\n\nThe relative benefit of binning increases with the size of the data.\n\n## Testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(1e4) + rnorm(1e4, -3, 0.7)\n\nplot(kern_dens(x, 0.2), type = \"l\", lwd = 4)\nlines(kern_dens_bin(x, 0.2), col = \"red\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/plot-kern-dens-benchmark-1.pdf)\n:::\n:::\n\n\n## Testing\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture3_files/figure-beamer/test-kern-dens-bench-1.pdf)\n:::\n:::\n\n\nThe absolute errors due to binning are small but increasing with decreasing\nlength of data sequence. Here $n = 8192$ is black, $n = 1024$ is red and\n$n = 128$ is blue.\n\n## Line Profiling\n\nThe `kern_dens_bin()` function is so much faster for long sequences that to get\ngood profiling results we use a 512 times longer data sequence.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(2^22)\n# profvis(kern_dens_bin(x, 0.2))\n```\n:::\n\n\n## Vectorization\n\n- Vectorization is the process of replacing loops with vectorized operations.\n- These vectorized operations are also loops, but they are written in C instead\n  or R.\n  - Examples of vectorized functions: `mean()`, `exp()`\n  - Examples of non-vectorized functions: `apply()`, `Vectorize()`\n- Vectorizing code is often about finding the right function in R.\n  - `colSums()` instead of for loop or apply-type of function.\n\n## Exercise on Vectorization\n\n- Vectorize the `kern_bin()` function\n- Benchmark the performance of the two functions.\n- **Hint:** Use `tabulate()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkern_bin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction(x, l, u, B) {\n  w <- numeric(B)\n  delta <- (u - l) / (B - 1)\n  for (j in seq_along(x)) {\n    i <- floor((x[j] - l) / delta + 0.5) + 1\n    w[i] <- w[i] + 1\n  }\n  w / sum(w)\n}\n<bytecode: 0x20a663f0>\n```\n\n\n:::\n:::\n\n\n\n\n## Avoiding Copies\n\n### Copy-on-Modify\n\n- In R, objects are passed by reference, but when an object is modified a copy\n  is created.\n- For instance, when subsetting a matrix, a copy is created. It's not possible\n  to access for instance a column by reference.\n- Growing vectors (`c()`) and matrices (`rbind()`, `cbind()`) creates copies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(100)\nx <- c(x, 4) # 101 values are allocated\n```\n:::\n\n\n## Memory\n\n### Memory in R\n\nIn R, everything is typically loaded into memory.\n\n### Garbage Collection\n\nR includes a garbage collector, which intermittently releases unused blocks in\nmemory.\n\n### Trade-Offs\n\nStoring intermediate objects that are used multiple times will boost performance\nat the cost of additional memory storage.\n\n## Exercise\n\nCan you rewrite the following function to avoid creating copies?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatrix_vector_dot\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction (x, y) \n{\n    p <- NCOL(x)\n    out <- c()\n    for (i in seq_len(p)) {\n        xi_y <- t(x[, i]) %*% y\n        out <- c(out, xi_y)\n    }\n    out\n}\n```\n\n\n:::\n:::\n\n\n## Storage Modes\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n- In R, matrices are stored in column-major order.\n- This is generally language-dependent.\n- This means that when you access a column of a matrix, you are accessing a\n  contiguous block of memory.\n- Some operations are faster with column-major order and others with row-major\n  order.\n\n:::\n\n::: {.column width=\"47%\"}\n\n:::\n\n::::\n\n## Exercise\n\nBenchmark the following three implementations of matrix-vector multiplication.\n\n1. Take the inner product of each row with the vector and sum up.\n2. First transpose the matrix and then take the inner product.\n3. Take the elementwise (Hadamard) product of each column of the matrix and\n   vector and sum up. --\n\n### Implementation of First Method\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatvecmul_v1 <- function(x, y) {\n  n <- NROW(x)\n  z <- double(n)\n\n  for (i in seq_len(n)) {\n    z[i] <- t(x[i, ]) %*% y\n  }\n  z\n}\n```\n:::\n\n\n\n\n## Concurrency\n\n- Modern processors today have multiple (physical and virtual) cores\n- But unless instructed otherwise, only a single core is going to be used.\n- The computer doesn't automatically know that your computations are safe to do\n  in parallel.\n\n## Embarassingly Parallel Tasks\n\nTrivial implementation of parallelization\n\nIt would be embarassing to miss the opportuity to parallelize the task.\n\n### Examples\n\n- Summing a vector (or matrix): `sum()`\n- Linear algebra operations: `%*%` (`crossprod()`)\n- Running iterations of a simulation\n- Cross-validation\n\n## The foreach Package\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(foreach)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = seq_len(3)) %dopar%\n  {\n    sqrt(i)\n  }\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1.414214\n\n[[3]]\n[1] 1.732051\n```\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n### Notes\n\n- Returns a list (so not really a for loop).\n- The warning tells us that actually nothing is parallel yet.\n- First, we need to register a **backend**.\n\n:::\n\n::::\n\n## Backends\n\n- Multiple backends, installed separately (**doParallel**, **doMC**,\n  **doFuture**)\n- Load and **register** one before using foreach\n- Windows user cannot use forking (which is cheaper)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(doParallel)\n\ncl <- makeCluster(2) # 2 is the number of threads requested\n# cl <- makeForkedCluster(2) # Only on non-Windows\n\nregisterDoParallel(cl)\n# registerDoParallel(cores = 4) # If not on Windows\n\nres <- foreach(i = seq_len(3)) %dopar%\n  {\n    cat(\"Hello from process\", Sys.getpid(), \"\\n\")\n  }\n```\n:::\n\n\n## Combining Results\n\n- `foreach()` always returns a list.\n- If you want to reduce your result, use either the `.combine` argument or\n  manually reduce the resulting list.\n\n. . .\n\n### `.combine`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(4, 1, 1e2, 2)\n\nforeach(i = seq_len(4), .combine = c) %dopar%\n  {\n    log(x[[i]])\n  }\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.3862944 0.0000000 4.6051702 0.6931472\n```\n\n\n:::\n:::\n\n\n## Exercise\n\n### Part 1\n\nWrite a parallelized version of `mean()`. The function should take a vector as\nit's first argument and a cluster object as the second argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar_mean <- function(x) {\n  n <- length(x)\n  # Your code here\n}\n```\n:::\n\n\n\n\n. . .\n\n### Part 2\n\nWrite a parallelized version of `lapply()`. Pass along arguments to the\nfunction.\n\n\n\n## Futures\n\n- An abstraction for a value that may be available at some point in the future.\n- Sometimes called promises: \"I promise to give you the result later.\"\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n### Without Futures\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- {\n  cat(\"Hello world!\\n\")\n  3.14\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nHello world!\n```\n\n\n:::\n\n```{.r .cell-code}\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.14\n```\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n### With Futures\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(future)\nv %<-%\n  {\n    cat(\"Hello world!\\n\")\n    3.14\n  }\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nHello world!\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.14\n```\n\n\n:::\n:::\n\n\n:::\n\n::::\n\n## Futures Enable Parallelization\n\n- To parallelize a computation, we can use futures.\n- A thread is created for each future.\n- Other work can be done in the meantime on main thread.\n- Once the value is needed, hopefully it is already (or best: just-in-time)\n  available.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession)\n\n# plan(multicore) # Not on Windows or RStudio!\n\nz %<-%\n  {\n    # Expensive computation\n  }\n\n# Other expensive computations\n\nz # Will block until the value is available\n```\n:::\n\n\n## Caveats Regarding Parallelization\n\n- Twice as many cores $\\neq$ twice as fast (in practice).\n  - Communication overhead\n  - Memory overhead\n- Thread safety\n- Parallelizing functions that are already parallelized internally typicall has\n  no (or negative) effect.\n\n## Exercise\n\nWrite a program for running ordinary least squares regression in parallel using\nthe **futures** package.\n\n**Recall:** The OLS estimator is given by $\\hat{\\beta} = (X^TX)^{-1}X^T y$.\n\n\n\n## Summary\n\n- First find bottlenecks through profiling\n- Benchmark different implementations and use existing solutions\n- Vectorize and use domain-specific knowledge to improve performance.\n\n. . .\n\n### Keep in Mind\n\n- Only optimize when it's needed: profile first\n- Keep readability in mind: performant code can be hard to read.\n- Write tests: performance improvements can introduce bugs.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}