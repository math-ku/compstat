{
  "hash": "8a54ca77c920cfc0452399c970f2d66d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Likelihood Optimization\"\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Today\n\n### Optimization for Multinomial Models\n\n- Likelihood optimization\n- Intro to constrained optimization\n\n# Multinomial Models\n\n## The Peppered Moth\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n### Alleles\n\nC, Ci, T with frequencies $p_C$, $p_I$, $p_T$ and $p_C + p_I + p_T = 1.$\n\n### Genotypes\n\nCC, CI, CT, II, IT, TT\n\n### Phenotypes\n\nBlack, mottled, light-colored\n\n:::\n\n::: {.column width=\"47%\"}\n\n![](../images/peppered-moth.jpg){width=100%}\n\n|       | C     | I       | T             |\n| ----- | ----- | ------- | ------------- |\n| **C** | Black | Black   | Black         |\n| **I** | Black | Mottled | Mottled       |\n| **T** | Black | Mottled | Light-colored |\n\n:::\n\n::::\n\n::: {.notes}\n\nThe Peppered Moth is called 'Birkemåler' in Danish. There is a nice collection\nof these in different colors in the Zoological Museum. The alleles are ordered\nin terms of dominance as C > I > T. Moths with genotype including C are dark.\nMoths with genotype TT are light colored. Moths with genotypes II and IT are\nmottled.\n\nThe peppered moth provided an early demonstration of evolution in the 19th\ncenture England, where the light colored moth was outnumered by the dark colored\nvariety. The dark color became advantageous due to the increased polution, where\ntrees were darkened by soot.\n\nhttps://en.wikipedia.org/wiki/Peppered_moth_evolution\n\n:::\n\n### Hardy–Weinberg Equilibrium\n\nAccording to the\n[Hardy–Weinberg equilibrium](https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle),\nthe genotype frequencies are\n$$p_C^2, 2p_Cp_I, 2p_Cp_T, p_I^2,  2p_Ip_T, p_T^2.$$\n\n. . .\n\nThe complete multinomial log-likelihood is $$ \\begin{aligned} &2n*{CC}\n\\log(p_C) + n*{CI} \\log (2 p*C p_I) + n*{CT} \\log(2 p*C p_I) \\\\ &+ 2 n*{II}\n\\log(p*I) + n*{IT} \\log(2p*I p_T) + 2 n*{TT} \\log(p_T), \\end{aligned}$$\n\n. . .\n\nWe only observe $(n_C, n_I, n_T)$, where\n\n$$\nn = \\underbrace{n_{CC} + n_{CI} + n_{CT}}_{= n_C} +\n\\underbrace{n_{IT} + n_{II}}_{=n_I} + \\underbrace{n_{TT}}_{=n_T}.\n$$\n\n. . .\n\nAs a specific data example we have the observation $n_C= 85$, $n_I = 196$, and\n$n_T = 341.$\n\n### Multinomial Cell Collapsing\n\nThe Peppered Moth example is an example of _cell collapsing_ in a multinomial\nmodel.\n\n. . .\n\nIn general, let $A_1 \\cup \\ldots \\cup A_{K_0} = \\{1, \\ldots, K\\}$ be a partition\nand let $$M : \\mathbb{N}_0^K \\to \\mathbb{N}_0^{K_0}$$ be the map given by\n$$M((n_1, \\ldots, n_K))_j = \\sum_{i \\in A_j} n_i.$$\n\n### Multinomial Distribution\n\nIf $Y \\sim \\textrm{Mult}(p, n)$ with $p = (p_1, \\ldots, p_K)$ then\n$$X = M(Y) \\sim \\textrm{Mult}(M(p), n).$$\n\n. . .\n\nFor the peppered moths, $K = 6$ corresponding to the six genotypes, $K_0 = 3$\nand the partition corresponding to the phenotypes is\n$$\\{1, 2, 3\\} \\cup \\{4, 5\\} \\cup \\{6\\} = \\{1, \\ldots, 6\\},$$ --\n\nand $$M(n_1, \\ldots, n_6) = (n_1 + n_2 + n_3, n_4 + n_5, n_6).$$\n\n### Cell Collapsing\n\nIn terms of the $(p_C, p_I)$ parametrization, $p_T = 1 - p_C - p_I$ and\n$$p = (p_C^2, 2p_Cp_I, 2p_Cp_T, p_I^2,  2p_Ip_T, p_T^2).$$\n\n. . .\n\nHence $$M(p) = (p_C^2 + 2p_Cp_I + 2p_Cp_T, p_I^2 +2p_Ip_T, p_T^2).$$\n\n. . .\n\nThe log-likelihood is,\n\n$$\n\\begin{aligned} \\ell(p_C, p_I) & = n_C \\log(p_C^2 +\n2p_Cp_I + 2p_Cp_T) \\\\ & \\phantom{={}}+ n_I \\log(p_I^2 +2p_Ip_T) + n_T \\log\n(p_T^2) \\end{aligned}\n$$\n\n### Standard Form\n\nThis is an optimization problem of the following standard form:\n\n$$\n\\begin{aligned}&\\operatorname*{minimize}_{p_C,p_I} && -\\ell(p_C, p_I) \\\\\n&\\operatorname*{subject to} && p_C + p_C - 1 \\leq 0\\\\\n&                           && -p_C \\leq 0\\\\\n&                           && -p_I \\leq 0\\\\\n&                           && p_I - 1 \\leq 0\\\\\n&                           && p_C -1 \\leq 0.\n\\end{aligned}\n$$\n\n. . .\n\n#### Convex?\n\n. . .\n\n**Yes**, because the negative log-likelihood is convex and so are the\nconstraints (affine).\n\n#### Can We Solve it Using Gradient Descent or Newton's Method?\n\n. . .\n\n**No** (not directly), since the problem is constrained.\n\n\n\n### Objective Surface\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture9_files/figure-beamer/surface-1.pdf)\n:::\n:::\n\n\n### Change of Variables?\n\nLet $$p_j = \\frac{\\exp{(\\theta_j)}}{\\sum_{i = 1}^K \\exp(\\theta_i)}.$$\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\nSeems like a good idea! Constraints are automatically satisfied.\n\n#### But... Convex?\n\n**No**, $f$ is no longer convex.\n\n:::\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture9_files/figure-beamer/unnamed-chunk-1-1.pdf)\n:::\n:::\n\n\n:::\n\n::::\n\n### Optimization\n\nSo, we cannot use our existing toolbox. What to do?\n\n. . .\n\nWe will try two different options.\n\n#### General Optimization\n\n- Define **extended-value** function, and use general (zero-order) optimization\n\n. . .\n\n#### Constrained Optimization (Barrier Method)\n\nUse the barrier method to directly solve the **constrained** optimization\nproblem.\n\n### Negative Log-Likelihood\n\nWe can code a problem-specific (extended-value) version of the negative\nlog-likelihood.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# x is the data vector of length 3 of counts\nneg_loglik_pep <- function(par, x) {\n  pC <- par[1]\n  pI <- par[2]\n  pT <- 1 - pC - pI\n\n  if (pC > 1 || pC < 0 || pI > 1 || pI < 0 || pT < 0) {\n    return(Inf)\n  }\n\n  p_dark <- pC^2 + 2 * pC * pI + 2 * pC * pT\n  p_mottled <- pI^2 + 2 * pI * pT\n  p_light <- pT^2\n\n  -(x[1] * log(p_dark) + x[2] * log(p_mottled) + x[3] * log(p_light))\n}\n```\n:::\n\n\n### Zero-Order Nelder-Mead\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(85, 196, 341)\nx0 <- c(1 / 3, 1 / 3)\n\noptim(x0, neg_loglik_pep, x = x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$par\n[1] 0.07082 0.18879\n\n$value\n[1] 600.5\n\n$counts\nfunction gradient \n      65       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n```\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n#### Feasible Starting Point\n\nSome thought has to go into the initial parameter choice.\n\n\n::: {.cell linewidth='38'}\n\n```{.r .cell-code}\noptim(\n  c(0, 0),\n  neg_loglik_pep,\n  x = x\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in optim(c(0, 0),\n\tneg_loglik_pep, x = x): function\n\tcannot be evaluated at initial\n\tparameters\n\t\n```\n\n\n:::\n:::\n\n\n:::\n\n::::\n\n### Log-Likelihood Function Factory\n\n`M()` sums the cells that are collapsed, which we specify in `group` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM <- function(y, group) {\n  as.vector(tapply(y, group, sum))\n}\n```\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmult_likelihood <- function(x, group, prob, constraint = function(par) TRUE) {\n  force(x)\n  force(group)\n  force(prob)\n\n  function(params) {\n    pr <- prob(params)\n    if (!constraint(params) || any(pr > 1) || any(pr < 0)) {\n      return(Inf)\n    }\n    -sum(x * log(M(pr, group)))\n  }\n}\n```\n:::\n\n\n### Peppered Moths Specifics\n\nProblem-specific functions\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n#### Multinomial Probabilities\n\n`prob()` maps parameters to the multinomial probability vector.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprob <- function(p) {\n  p[3] <- 1 - p[1] - p[2]\n  c(\n    p[1]^2,\n    2 * p[1] * p[2],\n    2 * p[1] * p[3],\n    p[2]^2,\n    2 * p[2] * p[3],\n    p[3]^2\n  )\n}\n```\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n#### Constraints\n\nCheck of constraints.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconstraint <- function(par) {\n  par[1] <= 1 &&\n    par[1] >= 0 &&\n    par[2] <= 1 &&\n    par[2] >= 0 &&\n    1 - par[1] - par[2] >= 0\n}\n```\n:::\n\n\n:::\n\n::::\n\n### Putting it All Together\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nneg_mult_loglik <- mult_likelihood(\n  x = x,\n  group = c(1, 1, 1, 2, 2, 3),\n  prob = prob,\n  constraint = constraint\n)\n```\n:::\n\n\n:::\n\n::: {.column width=\"47%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoth_optim <- optim(\n  x0,\n  neg_mult_loglik\n)\nmoth_optim\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$par\n[1] 0.07082 0.18879\n\n$value\n[1] 600.5\n\n$counts\nfunction gradient \n      65       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n```\n\n\n:::\n:::\n\n\n:::\n\n::::\n\n### Barrier Function\n\nSecond (and better) option is to use the barrier method.\n\nTransform\n\n$$\n\\begin{aligned}\n      & \\text{minimize}   &  & f(x)                               \\\\\n      & \\text{subject to} &  & g_i(x) \\leq 0, & \\quad i =1,\\dots,m. \\\\\n  \\end{aligned}\n$$\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\ninto\n\n$$\n\\begin{aligned}\n       \\text{minimize}   &  & tf(x) + \\phi(x)\n  \\end{aligned}\n$$\n\nwith the barrier function $$\\phi(z) = -\\sum_{i=1}^m \\log(-g_i(z)).$$\n\n:::\n\n::: {.column width=\"47%\"}\n\n![](../images/central-path.png){width=100%}\n\n:::\n\n::::\n\n### `constrOptim()`\n\nSolves problems with affine/linear inequality constraints of the form\n$$Ax \\succeq b$$ or, in terms of arguments: `ui %*% theta >= ci`.\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"47%\"}\n\n#### Moths Example\n\n$$\nA = \\begin{bmatrix}1 & 0\\\\-1 & 0\\\\0 & 1\\\\0 & -1\\\\ -1 & -1\\end{bmatrix},\n\\quad b = \\begin{bmatrix}0\\\\-1\\\\0\\\\-1\\\\-1\\end{bmatrix}.\n$$\n\n:::\n\n::: {.column width=\"47%\"}\n\n#### Optimization Problem\n\n$$\n\\begin{aligned}&\\operatorname*{minimize}_{p} && -\\ell(p) \\\\\n&\\operatorname*{subject to} && Ap  \\succeq b.\n\\end{aligned}\n$$\n\nwith $p = (p_C, p_I)$.\n\n:::\n\n::::\n\n. . .\n\n**Not** standard form, but what `constrOptim()` expects.\n\n### `constrOptim()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- rbind(\n  c(1, 0),\n  c(-1, 0),\n  c(0, 1),\n  c(0, -1),\n  c(-1, -1)\n)\n\nb <- c(0, -1, 0, -1, -1)\n\nconstrOptim(x0, neg_loglik_pep, NULL, ui = A, ci = b, x = x)$par\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.07082 0.18879\n```\n\n\n:::\n:::\n\n\n. . .\n\n#### Still Requires Feasible Initial Point\n\n\n::: {.cell linewidth='80'}\n\n```{.r .cell-code}\nconstrOptim(c(0.0, 0.3), neg_loglik_pep, NULL, ui = A, ci = b, x = x)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in constrOptim(c(0, 0.3), neg_loglik_pep, NULL, ui = A, ci = b, : initial\n\tvalue is not in the interior of the feasible region\n\t\n```\n\n\n:::\n:::\n\n\n## Interior-Point Method\n\n### Phase I: Initialization\n\nFind a feasible point $x^{(0)}$ by solving the optimization problem\n\n$$\n\\begin{aligned}&\\operatorname*{minimize}_{(x,s)} && s \\\\\n&\\operatorname*{subject to} && g_i(x) \\leq s, & \\quad i = 1, \\dots, m.\\end{aligned}\n$$\n\n. . .\n\nIf $s^* \\leq 0$, then $x^* = x^{(0)}$ is feasible.\n\n. . .\n\nEasy in the peppered moths case! But this is not always the case.\n\n. . .\n\n### Phase II: Barrier Method\n\nUse a barrier method to solve the constrained problem, starting at $x^{(0)}$.\n\n## Multinomial Conditional Distributions\n\nDistribution of $Y_{A_j} = (Y_i)_{i \\in A_j}$ conditional on $X$ can be found\ntoo:\n$$Y_{A_j} \\mid X = x \\sim \\textrm{Mult}\\left( \\frac{p_{A_j}}{M(p)_j}, x_j \\right).$$\n\n. . .\n\n### Expected Genotype Frequencies\n\nHence for $k \\in A_j$,\n$$\\operatorname{E} (Y_k \\mid X = x) = \\frac{x_j p_k}{M(p)_j}.$$\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroup <- c(1, 1, 1, 2, 2, 3)\np <- prob(moth_optim$par)\nx[group] * p / M(p, group)[group]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]   3.12  16.64  65.24  22.16 173.84 341.00\n```\n\n\n:::\n:::\n\n\n## Summary\n\n- Peppered moths example is simple and the log-likelihood for the observed data\n  can easily be computed.\n- Constrained optmimization can be solved using the barrier method.\n- `optim()` in R is general interface to optimization methods.\n- `constOptim()` is used for linearly constrained optimization.\n\n## Exercise: Absolute-Value Constraints\n\nSolve the following optimization problem:\n\n$$\n\\begin{aligned}\n  &\\operatorname*{minimize}_{x}              && \\frac{1}{2}(x - 2)^2 \\\\\n  &\\operatorname{subject to} && |x| \\leq 1.\n\\end{aligned}\n$$\n\n### Steps\n\n- First rewrite the problem in standard form.\n- Then use `constrOptim()` with `ui` and `ci` arguments to specify the\n  constraints.\n- If you have time, try implementing the barrier method yourself on top of a\n  gradient descent method.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}