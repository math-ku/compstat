---
title: "Benchmarking and Profiling"
subtitle: Computational Statistics
author: "Johan Larsson, Niels Richard Hansen"
date: "September 10, 2024"
---

```{r setup, echo=FALSE}
source(file.path("R", "kernel.R"))

knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.8,
  fig.retina = 3,
  fig.align = "center",
  cache = FALSE,
  autodep = TRUE,
  dev.args = list(pointsize = 16),
  crop = TRUE
)

library(ggplot2)

theme_set(theme_grey(base_size = 16))
```

## Today


### Measuring Performance

#### Profiling

Identifying bottlenecks in code

#### Benchmarking

Comparing performance of different implementations

--

### Improving Performance

Writing efficient code


---
## Profiling

A profiler quantifies how much time each part of a function takes up.

--

R uses a *sampling profiler* which at regular time intervals records which 
function is currently executing.

--

The R package [profvis](https://CRAN.R-project.org/package=profvis) provides useful visualization tools of the data generated 
by the profiler. Can also be called activated through the RStudio IDE.

```{r load_profvis}
library(profvis)
```

--

### Remember!

> We *should* forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.
> Yet we should not pass up our opportunities in that critical 3%.
> 
> *—Donald Knuth*

---

## Example

We profile the following reimplementation of `gauss()`.

```{r gauss_step, eval=FALSE, out.width = 600}
gauss_step <- function(x, h = 1) {
  exponent <- x^2 / (2 * h^2)
  numerator <- exp(-exponent)
  denominator <- h * sqrt(2 * pi)
  numerator / denominator
}
```

---
## Example

```{r source_profvis, cache = TRUE, eval = FALSE}
source("R/Lecture.R", keep.source = TRUE)
x <- rnorm(1e7)
profvis(gauss_step(x))
```

---

## Exercise

Consider the implementation of `kern_dens()`.

```{r kern_dens_impl}
kern_dens <- function(x, h, m = 512) {
  grid_points <- seq(min(x) - 3 * h, max(x) + 3 * h, length.out = m)
  y <- numeric(m)
  for (i in seq_along(grid_points)) {
    for (j in seq_along(x)) {
      y[i] <- y[i] + exp(-(grid_points[i] - x[j])^2 / (2 * h^2))
    }
  }
  y <- y / (sqrt(2 * pi) * h * length(x))
  list(x = grid_points, y = y)
}
```

Use line profiling on this function to investigate where most
time is spent. 


---
## Line Profiling

The `profvis` package can summarize profiling information 
by line in the source code. The following code will open a 
profiling display when evaluated in RStudio. 

```{r profile_kern_dens, eval=FALSE}
library("profvis")
profvis(kern_dens(x, 0.2))
```

The [result](kern_dens_prof.html) is an interactive HTML page, which can be saved and viewed in a browser.

---
## Line Profiling

The one-liner in the loop did too many things. The `kern_dens_detail()` spells out
the steps in this condensed expression.

```{r kern_dens_detail, echo=FALSE}
kern_dens_detail
```

---
## Line Profiling

```{r profile_kern_dens_detail, eval=FALSE}
profvis(kern_dens_detail(x, 0.2))
```

The [result](kern_dens_detail_prof.html) of profiling the code for this function call 
is more informative.

--

You should compare the profiling result above with the 
[result from the initial `kern_dens`](kern_dens_prof.html) implementation. 


---

## Binning

The line profiler revealed that most time is spent on the 
kernel evaluation. 

--

A trick to reduce the $nm$ kernel evaluations to a smaller number is
**binning**.

--


(On the slides and in my implementations, $m$ denotes the number of grid points 
for the evaluation of the estimate and $n$ the length of the data vector.)

If $n < m$, then binning may not be beneficial.

---

## Benchmarking

The purpose of benchmarking is to measure and compare the computational resources 
used by one or more implementations of a computation.

--

### Microbenchmarking

Benchmarking small pieces of code.

### The bench Package

We will use the R package [bench](https://cran.r-project.org/web/package=bench) for benchmarking.

```{r}
library(bench)
```

---
## Example

```{r}
x <- runif(100)

bench::mark(
  sqrt(x),
  x^0.5
)
```

---
## Exercise

Consider the following implementation of the Gaussian kernel.

```{r}
gauss <- function(x, h = 1) {
  exp(-x^2 / (2 * h^2)) / (h * sqrt(2 * pi))
}
```

Benchmark `gauss()` against `dnorm()`. 

```{r, include = FALSE}
x <- seq(-3, 3, length.out = 10000)

bench::mark(
  gauss(x),
  dnorm(x)
)
```

---

## Benchmarking Density Estimation

```{r message = FALSE, cache = FALSE}
res <- bench::press(
  n = 2^(5:13),
  {
    x <- rnorm(2^13)
    bench::mark(
      base = density(x[1:n], 0.2),
      loop = kern_dens(x[1:n], 0.2),
      vectorized = kern_dens_vec(x[1:n], 0.2),
      check = FALSE
    )
  }
)
```

---

```{r, echo=FALSE, warning=FALSE}
library(tidyverse)
mutate(
  res,
  expr = as.character(expression),
  median = as.numeric(median)
) |>
  ggplot(aes(n, median, color = expr)) +
  geom_point() +
  geom_line() +
  scale_y_log10() +
  labs(y = "time (µs)")
```

[Source for R code](R/kernel.R)

---
## Binning

```{r}
kern_bin
```

The `kern_bin()` function is a loop along the data vector, and 
arithmetic is used to determine which bin center is closest to a 
data point. 

--

The `kern_dens_bin()` function (see [the source file](R/kernel.R)) computes bin weights 
using `kern_bin()` with grid points as bin centers. 

---

```{r micro3, cache = TRUE, echo=FALSE, message=FALSE}
res2 <- bench::press(
  n = 2^(5:13),
  {
    h <- 0.2
    x <- rnorm(n)
    bench::mark(
      base = density(x, h),
      loop = kern_dens(x, h),
      vectorized = kern_dens_vec(x, h),
      binning = kern_dens_bin(x, h),
      check = FALSE
    )
  }
)

mutate(
  res2,
  expr = as.character(expression),
  median = as.numeric(median)
) |>
  ggplot(aes(n, median, color = expr)) +
  geom_point() +
  geom_line() +
  scale_y_log10() +
  labs(y = "time (µs)")
```

The relative benefit of binning increases with the size of the data.

---
## Testing

```{r plot-kern-dens-benchmark, echo=-c(1:2), fig.width = 7, fig.asp = 0.7}
library(tidyverse)
set.seed(123)
x <- rnorm(1e4) + rnorm(1e4, -3, 0.7)

plot(kern_dens(x, 0.2), type = "l", lwd = 4)
lines(kern_dens_bin(x, 0.2), col = "red", lwd = 2)
```

---
## Testing

```{r test-kern-dens-bench, echo=FALSE, fig.width=7, fig.asp = 0.65}
x0 <- kern_dens(x, 0.2)$x
plot(
  x0,
  kern_dens(x, 0.2)$y - kern_dens_bin(x, 0.2)$y,
  type = "l",
  ylim = c(-3e-3, 3e-3),
  lwd = 2,
  ylab = "Difference"
)
lines(
  x0,
  kern_dens(x[1:1024], 0.2)$y - kern_dens_bin(x[1:1024], 0.2)$y,
  col = "red",
  lwd = 2
)
lines(
  x0,
  kern_dens(x[1:128], 0.2)$y - kern_dens_bin(x[1:128], 0.2)$y,
  col = "blue",
  lwd = 2
)
```

The absolute errors due to binning are small but increasing with 
decreasing length of data sequence. Here $n = 8192$ is black, $n = 1024$ 
is red and $n = 128$ is blue. 

---
## Line profiling

The `kern_dens_bin()` function is so much faster for long sequences that to get good 
profiling results we use a 512 times longer data sequence.

```{r, eval=FALSE}
x <- rnorm(2^22)
profvis(kern_dens_bin(x, 0.2))
```

The [result](kern_dens_bin_prof.html) shows that now the largest fraction of time was spent 
in the binning algorithm.

---

## Caveats About Profiling

- Anonymous functions make profiling more difficult; prefer using named functions.
- Resolution may not be enough for small pieces of code (but do you really need to profile them then?)

---

class: center, middle

# Improving Performance

---

## Vectorization

- Vectorization is the process of replacing loops with vectorized operations.

- These vectorized operations are also loops, but they are written in C instead or R.
  - Examples of vectorized functions: `mean()`, `sd()`
  - Examples of non-vectorized functions: `apply()`, `Vectorize()`

- Vectorizing code is often about finding the right function in R.

---

## Exercise on Vectorization



---

## Avoiding Copies

- In R, objects are passed by reference, but when an object is modified a copy is created.
--

- For instance, when subsetting a matrix, a copy is created. It's not possible to access for instance a column by reference.
--

- Growing vectors (`c()`) and matrices (`rbind()`, `cbind()`) also creates copies.


```{r}
x <- rnorm(100)
x <- c(x, 4) # 101 values are allocated
```

---

## Memory

### Memory in R

In R, everything is typically loaded into memory.

### Garbage Collection

R includes a garbage collector, which intermittently releases unused blocks in memory.

### Trade-Offs

Storing intermediate objects that are used multiple times will boost performance at the cost of additional memory storage.

---

## Exercise

Let's say we want to minimize the following function with gradient descent:
$$f(x) = \frac{1}{2}x^2 - x.$$
The gradient is $f'(x) = x - 1$.

```{r}
my_optim <- function(x) {
  gradient_history <- c()

  while (TRUE) {
    gradient <- x - 1
    gradient_history <- c(gradient_history, gradient)

    x <- x - g

    if (abs(g) < 1e-6) {
      break
    }
  }

  x
}
```


---

## Storage Modes

.pull-left[
- In R, matrices are stored in column-major order.
- This means that when you access a column of a matrix, you are accessing a contiguous block of memory.
- Prefer to work with matrices instead of data frames.
]
]

.pull-right[

]

---

## Exercise

```{r}
mat_vec_mul1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}
```


```{r, include = FALSE}
n <- 1e3
p <- 1e1

x <- matrix(rnorm(n * p), n)
y <- matrix(rnorm(p), p, 1)

f1 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- t(x[i, ]) %*% y
  }
  z
}

f2 <- function(x, y) {
  n <- NROW(x)
  x_t <- t(x)
  z <- double(n)

  for (i in seq_len(n)) {
    z[i] <- x_t[, i] %*% y
  }

  z
}

f3 <- function(x, y) {
  n <- NROW(x)
  z <- double(n)

  for (i in seq_len(NCOL(x))) {
    z <- z + x[, i] * y[i]
  }

  z
}

bench::mark(f1(x, y), f2(x, y), f3(x, y))
```

---

## Parallelization and Asynchronous Programming

- Modern processors today have multiple (physical and virtual) cores
--

- But unless instructed otherwise, only a single core is going to be used.

--

- The computer doesn't automatically know that your computations are safe to do in parallel.

### Embarassingly Parallel

Means that parallelizing the operation is trivial

Examples:

- Summing a vector (or matrix): `sum()`
- Linear algebra operations: `%*%` (`crossprod()`)

---

class: center, middle

# More on Functions and Scoping

---

## Functions 

R functions consist of three components.

```{r foo_function}
foo <- function(x) {
  x^2 + x + 1
}
```

* The *body* of the function, which is the code in the function.
--


* The *argument list* that the function takes.
--


* The *enclosing environment* where the function was created.

---
## Functions

```{r}
body(foo)
```

--
```{r}
formals(foo) ## formal argument list
```

--
```{r}
environment(foo) ## enclosing environment
```


---
## Function evaluation

When functions are called the body is evaluated with formal arguments 
replaced by actual arguments (values).


```{r}
foo(10) ## body evaluated with x = 10
```

--
The result is the same as: 

```{r}
x <- 10
x^2 + x + 1
```

---
## A different function body


```{r}
foo <- function(x) {
  y * x^2 + x + 1
}
```

What happens when we try to evaluate the new function?

--
```{r, error = TRUE}
foo(10)
```

--
```{r}
y <- 2 ## y is in the global environment
foo(10)
```

--
Variables that are not assigned in the body or are in the list of formal 
arguments are searched for in the functions *enclosing environment*.

---
## Changing the enclosing environment

The enclosing environment can be changed, and values can be
assigned to variables in environments.

```{r, error = TRUE}
environment(foo) <- new.env()
environment(foo)$y <- 1
```

--
```{r}
y
```

--
```{r, eval=FALSE}
foo(10) ## What is the result and why?
```

--
```{r, echo=FALSE}
foo(10)
```

---
## A different set of formal arguments

```{r}
foo <- function(x, y) {
  y * x^2 + x + 1
}
```

--
```{r, eval=FALSE}
foo(10) ## What will happen?
```

--
```{r, echo=FALSE, error = TRUE}
foo(10)
```

--
```{r}
foo(10, 2) ## Better?
```

---
## How functions work in principle

* When a function is called, the actual arguments are matched against the *formal 
arguments*.
--


* Expressions in the actual argument list are evaluated in the *calling environment*.
--


* Then the *body* of the function is evaluated.
--


* Variables that are not arguments or defined inside the body are searched for 
in the *enclosing environment*.
--


* The value of the last expression in the body is returned by the function.

--

```{r, eval=FALSE}
foo(10, y^2)
```

--
```{r, echo=FALSE}
foo(10, y^2)
```

---
## Scoping Rules

For a variable we distinguish between the *symbol* (the `y`) and its value (`2`). 
The rules for finding the symbol are called *scoping* rules, and R implements *lexical scoping*.

--

Symbols reside in environments, and when a function call is evaluated 
R searches for symbols in the environment 
where the function is *defined* and *not* where it is called.

--

In practice, symbols are recursively searched for by starting in the functions *evaluation 
environment*, then its *enclosing environment* and so on until the empty environment. 

--

For interactive usage lexical scoping can appear strange. Setting "global variables"
might not have the "expected effect" if that is *dynamic scoping*, which is difficult to 
predict and reason about as a programmer. 

---
## Function Factories

```{r}
foo_factory <- function(y) {
  function(x) {
    y * x^2 + x + 1
  }
}
```
--

```{r}
foo <- foo_factory(2)
body(foo)
foo(10)
```

```{r}
foo2 <- foo_factory(3)
```


---
## Function Factories

```{r}
foo2(10)
```

--
```{r}
y <- 1
foo(10)
foo2(10)
```

Setting a value of `y` in the calling environment of `foo` or `foo2` doesn't
change the behavior of the functions.

---
## Function Factories

```{r}
environment(foo)
```
--

```{r}
ls(environment(foo))
```
--

```{r}
environment(foo)$y
```
--

The function `foo_factor()` is called a function factory because it returns (produces)
functions.

--

It's a way to provide a function with a local storage (its environment) for "configuration 
values".

---
## Function Factories

```{r}
environment(foo2)
```

Two different functions produced by the function factory have different enclosing 
environments. 

--

```{r}
parent.env(environment(foo2))
parent.env(environment(foo))
```

The parent environment is the enclosing environment of the factory, in this 
case the global environment. 
